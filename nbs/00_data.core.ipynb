{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "> This model contains all the necessary functionality for managing data. @Nathan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import icodegen\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from subprocess import CalledProcessError, check_output\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers, processors\n",
    "from typing import Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>docstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21559</th>\n",
       "      <td>public static &lt;T&gt; T defaultValue(Class&lt;T&gt; prim...</td>\n",
       "      <td>Returns the boxed default value for a primitiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>public com.google.protobuf.ByteString\\n      g...</td>\n",
       "      <td>&lt;pre&gt;\\nExplanation of why it was deprecated an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>public void setMaxPayloadSize(int max) {\\n    ...</td>\n",
       "      <td>Sets the maximum payload size in bytes.\\n\\n@pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16801</th>\n",
       "      <td>public synchronized void fit(MultiDataSetItera...</td>\n",
       "      <td>Fit the ComputationGraph using a MultiDataSetI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10601</th>\n",
       "      <td>public static boolean isSubtype(final Class&lt;? ...</td>\n",
       "      <td>Checks if the specified type is a descendant f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    code  \\\n",
       "21559  public static <T> T defaultValue(Class<T> prim...   \n",
       "7041   public com.google.protobuf.ByteString\\n      g...   \n",
       "193    public void setMaxPayloadSize(int max) {\\n    ...   \n",
       "16801  public synchronized void fit(MultiDataSetItera...   \n",
       "10601  public static boolean isSubtype(final Class<? ...   \n",
       "\n",
       "                                               docstring  \n",
       "21559  Returns the boxed default value for a primitiv...  \n",
       "7041   <pre>\\nExplanation of why it was deprecated an...  \n",
       "193    Sets the maximum payload size in bytes.\\n\\n@pa...  \n",
       "16801  Fit the ComputationGraph using a MultiDataSetI...  \n",
       "10601  Checks if the specified type is a descendant f...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "from ds4se.mgmnt.prep.i import jsonl_list_to_dataframe, get_dfs\n",
    "\n",
    "path = Path('/home/nathan/Downloads/')\n",
    "df_trn, df_val, df_tst = get_dfs(path/\"java/final/jsonl\")\n",
    "\n",
    "sample = 0.01\n",
    "df_trn = df_trn.sample(frac = sample)\n",
    "df_val = df_val.sample(frac = sample)\n",
    "df_tst = df_tst.sample(frac = sample)\n",
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4545, 153, 269)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "len(df_trn), len(df_val), len(df_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "df_fake = pd.DataFrame(['this is a test', 'भारत test'], columns = ['code']);df_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _isASCII(mthd: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the given method contains only ASCII characters. From https://stackoverflow.com/a/27084708/5768407.\n",
    "\n",
    "    :param mthd: the method to verify contains only ASCII characters\n",
    "    :returns: returns a boolean representing whether or not the given method contains only ASCII characters\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mthd.encode(encoding = 'utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def remove_non_ascii(df: pd.DataFrame, n: Optional[int] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove all methods that contain non-ascii characters from a given pandas dataframe, not in-place.\n",
    "\n",
    "    :param df: the pandas dataframe containing each method to be beautified\n",
    "    :param n: the number of methods to evaluate. If none, the entire dataframe will be used\n",
    "    :returns: returns a new dataframe without methods that contain non-ascii characters\n",
    "    \"\"\"\n",
    "    if n is None: n = len(df)\n",
    "\n",
    "    df = df.iloc[:n].copy()\n",
    "    df = df[df.code.apply(_isASCII)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_ASCII_DF = pd.DataFrame(['this is a test'], columns = ['code'])\n",
    "df_non_ascii = remove_non_ascii(df_fake)\n",
    "\n",
    "assert (NON_ASCII_DF == df_non_ascii).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%time df_trn = remove_non_ascii(df_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>public void setPipelines(java.util.Collection&lt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                code\n",
       "0  public void setPipelines(java.util.Collection<..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "df_fake = pd.DataFrame([\n",
    "    '''public void setPipelines(java.util.Collection<Pipeline> pipelines) {\n",
    "        if (pipelines == null) {\n",
    "            this.pipelines = null;\n",
    "            return;\n",
    "        }\n",
    "\n",
    "        this.pipelines = new com.amazonaws.internal.SdkInternalList<Pipeline>(pipelines);\n",
    "    }\n",
    "    '''\n",
    "], columns = ['code']); df_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _beautify(mthd: str) -> str:\n",
    "    \"\"\"\n",
    "    Beautifies a given method using uncrustify with the sun.cfg style, i.e., Oracle's style.\n",
    "\n",
    "    :param mthd: the method to beautify\n",
    "    :returns: returns a beautified version of the given method\n",
    "    \"\"\"\n",
    "    # get path of icodegen\n",
    "    icodegen_path = Path(icodegen.__path__[0])\n",
    "\n",
    "    # create tmp file to store df contents for training tokenizer\n",
    "    tmp_path = Path('/tmp')\n",
    "    tmp_path.mkdir(parents = True, exist_ok = True)\n",
    "    with open(tmp_path/'tmp.java', 'w') as f:\n",
    "        f.write(mthd)\n",
    "\n",
    "    try:\n",
    "        beaut_mthd = check_output([\n",
    "            icodegen_path/'uncrustify', '-c', icodegen_path/'sun.cfg',\n",
    "            '-f', tmp_path/'tmp.java'\n",
    "        ]).decode('utf-8')\n",
    "    except CalledProcessError as e:\n",
    "        # Exception thrown when the method is malformed, i.e, it is missing a curly brace\n",
    "        beaut_mthd = e.output.decode('utf-8')\n",
    "\n",
    "    return beaut_mthd\n",
    "\n",
    "def beautify_code(df: pd.DataFrame, n: Optional[int] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Beautify the methods in a pandas dataframe using uncrustify with the sun.cfg style, i.e., Oracle's style, not in-place.\n",
    "\n",
    "    :param df: the pandas dataframe containing each method to be beautified\n",
    "    :param n: the number of methods to evaluate. If none, the entire dataframe will be used\n",
    "    :returns: returns a modified dataframe with the methods beautified\n",
    "    \"\"\"\n",
    "    if n is None: n = len(df)\n",
    "\n",
    "    df = df.iloc[:n].copy()\n",
    "    df.code = df.code.apply(_beautify)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEAUT_MTHD = '''public void setPipelines(java.util.Collection<Pipeline> pipelines) {\n",
    "    if (pipelines == null) {\n",
    "\tthis.pipelines = null;\n",
    "\treturn;\n",
    "    }\n",
    "    this.pipelines = new com.amazonaws.internal.SdkInternalList<Pipeline>(\n",
    "\tpipelines);\n",
    "}\n",
    "'''\n",
    "\n",
    "df_beaut = beautify_code(df_fake)\n",
    "\n",
    "assert BEAUT_MTHD == df_beaut.code.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# %time df_beaut = beautify_code(df_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "idx = 0\n",
    "print(df_trn.code.values[idx])\n",
    "print(df_beaut.code.values[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# dicts of special tokens we are adding to the tokenizers so they do not get split\n",
    "\n",
    "extra_tokens = {\n",
    "    '<n>': '\\n'\n",
    "}\n",
    "\n",
    "# from https://docs.oracle.com/javase/tutorial/java/nutsandbolts/_keywords.html\n",
    "java_reserved_tokens = {\n",
    "    '<abstract>': 'abstract', '<assert>': 'assert', '<boolean>': 'boolean',\n",
    "    '<break>': 'break', '<byte>': 'byte', '<case>': 'case',\n",
    "    '<catch>': 'catch', '<char>': 'char', '<class>': 'class',\n",
    "    '<const>': 'const', '<continue>': 'continue', '<default>': 'default',\n",
    "    '<do>': 'do', '<double>': 'double', '<else>': 'else',\n",
    "    '<enum>': 'enum', '<extends>': 'extends', '<final>': 'final',\n",
    "    '<finally>': 'finally', '<float>': 'float', '<for>': 'for',\n",
    "    '<goto>': 'goto', '<if>': 'if', '<implements>': 'implements',\n",
    "    '<import>': 'import', '<instanceof>': 'instanceof', '<int>': 'int',\n",
    "    '<interface>': 'interface', '<long>': 'long', '<native>': 'native',\n",
    "    '<new>': 'new', '<package>': 'package', '<private>': 'private',\n",
    "    '<protected>': 'protected', '<public>': 'public', '<return>': 'return',\n",
    "    '<short>': 'short', '<static>': 'static', '<strictfp>': 'strictfp',\n",
    "    '<super>': 'super', '<switch>': 'switch', '<synchronized>': 'synchronized',\n",
    "    '<this>': 'this', '<throw>': 'throw', '<throws>': 'throws',\n",
    "    '<transient>': 'transient', '<try>': 'try', '<void>': 'void',\n",
    "    '<volatile>': 'volatile', '<while>': 'while'\n",
    "}\n",
    "\n",
    "# from https://docs.oracle.com/javase/tutorial/java/nutsandbolts/opsummary.html\n",
    "java_operator_tokens = {\n",
    "    '<=>': '=', '<+>': '+', '<->': '-',\n",
    "    '<*>': '*', '</>': '/', '<%>': '%',\n",
    "    '<++>': '++', '<-->': '--', '<!>': '!',\n",
    "    '<==>': '==', '<!=>': '!=', '<greater>': '>',\n",
    "    '<greater_equal>': '>=', '<lesser>': '<', '<lesser_equal>': '<=',\n",
    "    '<&&>': '&&', '<||>': '||', '<?>': '?',\n",
    "    '<:>': ':', '<~>': '~', '<double_lesser>': '<<',\n",
    "    '<double_greater>': '>>', '<triple_greater>': '>>>', '<&>': '&',\n",
    "    '<^>': '^', '<|>': '|'\n",
    "}\n",
    "\n",
    "java_structural_tokens = {\n",
    "    '<{>': '{', '<}>': '}', '<[>': '[',\n",
    "    '<]>': ']', '<lesser>': '<', '<greater>': '>',\n",
    "    '<(>': '(', '<)>': ')', '<;>': ';'\n",
    "}\n",
    "\n",
    "java_extra_tokens = {\n",
    "    '<@>': '@', '<...>': '...',\n",
    "    '<null>': 'null', '<true>': 'true', '<false>': 'false'\n",
    "}\n",
    "\n",
    "# combination of all dictionaries\n",
    "java_special_tokens = {\n",
    "    **java_reserved_tokens, **java_operator_tokens, **java_structural_tokens,\n",
    "    **java_extra_tokens, **extra_tokens\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt;&gt;&gt; &gt; + public ++ \\n\\n \\t \\t \\t\\t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  code\n",
       "0  >>> > + public ++ \\n\\n \\t \\t \\t\\t  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "df_fake = pd.DataFrame(['>>> > + public ++ \\n\\n \\t \\t \\t\\t  '], columns = ['code']); df_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['synchronized',\n",
       " 'implements',\n",
       " 'instanceof',\n",
       " 'interface',\n",
       " 'protected',\n",
       " 'transient',\n",
       " 'abstract',\n",
       " 'continue',\n",
       " 'strictfp',\n",
       " 'volatile',\n",
       " 'boolean',\n",
       " 'default',\n",
       " 'extends',\n",
       " 'finally',\n",
       " 'package',\n",
       " 'private',\n",
       " 'assert',\n",
       " 'double',\n",
       " 'import',\n",
       " 'native',\n",
       " 'public',\n",
       " 'return',\n",
       " 'static',\n",
       " 'switch',\n",
       " 'throws',\n",
       " 'break',\n",
       " 'catch',\n",
       " 'class',\n",
       " 'const',\n",
       " 'final',\n",
       " 'float',\n",
       " 'short',\n",
       " 'super',\n",
       " 'throw',\n",
       " 'while',\n",
       " 'false',\n",
       " 'byte',\n",
       " 'case',\n",
       " 'char',\n",
       " 'else',\n",
       " 'enum',\n",
       " 'goto',\n",
       " 'long',\n",
       " 'this',\n",
       " 'void',\n",
       " 'null',\n",
       " 'true',\n",
       " 'for',\n",
       " 'int',\n",
       " 'new',\n",
       " 'try',\n",
       " '>>>',\n",
       " '...',\n",
       " 'do',\n",
       " 'if',\n",
       " '++',\n",
       " '--',\n",
       " '==',\n",
       " '!=',\n",
       " '>=',\n",
       " '<=',\n",
       " '&&',\n",
       " '||',\n",
       " '<<',\n",
       " '>>',\n",
       " '=',\n",
       " '+',\n",
       " '-',\n",
       " '*',\n",
       " '/',\n",
       " '%',\n",
       " '!',\n",
       " '>',\n",
       " '<',\n",
       " '?',\n",
       " ':',\n",
       " '~',\n",
       " '&',\n",
       " '^',\n",
       " '|',\n",
       " '{',\n",
       " '}',\n",
       " '[',\n",
       " ']',\n",
       " '(',\n",
       " ')',\n",
       " ';',\n",
       " '@',\n",
       " '\\n']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(java_special_tokens.values(), key = len, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(java_special_tokens.values(), key = len, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<synchronized>', 'synchronized'),\n",
       " ('<implements>', 'implements'),\n",
       " ('<instanceof>', 'instanceof'),\n",
       " ('<interface>', 'interface'),\n",
       " ('<protected>', 'protected'),\n",
       " ('<transient>', 'transient'),\n",
       " ('<abstract>', 'abstract'),\n",
       " ('<continue>', 'continue'),\n",
       " ('<strictfp>', 'strictfp'),\n",
       " ('<volatile>', 'volatile'),\n",
       " ('<boolean>', 'boolean'),\n",
       " ('<default>', 'default'),\n",
       " ('<extends>', 'extends'),\n",
       " ('<finally>', 'finally'),\n",
       " ('<package>', 'package'),\n",
       " ('<private>', 'private'),\n",
       " ('<assert>', 'assert'),\n",
       " ('<double>', 'double'),\n",
       " ('<import>', 'import'),\n",
       " ('<native>', 'native'),\n",
       " ('<public>', 'public'),\n",
       " ('<return>', 'return'),\n",
       " ('<static>', 'static'),\n",
       " ('<switch>', 'switch'),\n",
       " ('<throws>', 'throws'),\n",
       " ('<break>', 'break'),\n",
       " ('<catch>', 'catch'),\n",
       " ('<class>', 'class'),\n",
       " ('<const>', 'const'),\n",
       " ('<final>', 'final'),\n",
       " ('<float>', 'float'),\n",
       " ('<short>', 'short'),\n",
       " ('<super>', 'super'),\n",
       " ('<throw>', 'throw'),\n",
       " ('<while>', 'while'),\n",
       " ('<false>', 'false'),\n",
       " ('<byte>', 'byte'),\n",
       " ('<case>', 'case'),\n",
       " ('<char>', 'char'),\n",
       " ('<else>', 'else'),\n",
       " ('<enum>', 'enum'),\n",
       " ('<goto>', 'goto'),\n",
       " ('<long>', 'long'),\n",
       " ('<this>', 'this'),\n",
       " ('<void>', 'void'),\n",
       " ('<null>', 'null'),\n",
       " ('<true>', 'true'),\n",
       " ('<for>', 'for'),\n",
       " ('<int>', 'int'),\n",
       " ('<new>', 'new'),\n",
       " ('<try>', 'try'),\n",
       " ('<triple_greater>', '>>>'),\n",
       " ('<...>', '...'),\n",
       " ('<do>', 'do'),\n",
       " ('<if>', 'if'),\n",
       " ('<++>', '++'),\n",
       " ('<-->', '--'),\n",
       " ('<==>', '=='),\n",
       " ('<!=>', '!='),\n",
       " ('<greater_equal>', '>='),\n",
       " ('<lesser_equal>', '<='),\n",
       " ('<&&>', '&&'),\n",
       " ('<||>', '||'),\n",
       " ('<double_lesser>', '<<'),\n",
       " ('<double_greater>', '>>'),\n",
       " ('<=>', '='),\n",
       " ('<+>', '+'),\n",
       " ('<->', '-'),\n",
       " ('<*>', '*'),\n",
       " ('</>', '/'),\n",
       " ('<%>', '%'),\n",
       " ('<!>', '!'),\n",
       " ('<greater>', '>'),\n",
       " ('<lesser>', '<'),\n",
       " ('<?>', '?'),\n",
       " ('<:>', ':'),\n",
       " ('<~>', '~'),\n",
       " ('<&>', '&'),\n",
       " ('<^>', '^'),\n",
       " ('<|>', '|'),\n",
       " ('<{>', '{'),\n",
       " ('<}>', '}'),\n",
       " ('<[>', '['),\n",
       " ('<]>', ']'),\n",
       " ('<(>', '('),\n",
       " ('<)>', ')'),\n",
       " ('<;>', ';'),\n",
       " ('<@>', '@'),\n",
       " ('<n>', '\\n')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(java_special_tokens.items(), key = lambda x: len(x[1]), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _replace_toks(mthd: str, spec_toks: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Helper function for replacing all special tokens in a given method. This will replace longer special tokens first in order to not mistakenly breakup a special token that is part of a longer sequence. Adapted from https://stackoverflow.com/a/6117124/5768407 and https://stackoverflow.com/a/11753945/5768407\n",
    "\n",
    "    :param mthd: the method to have its special tokens replaced\n",
    "    :param spec_toks: a dictionary containing the special tokens to replace and the new tokens to replace them with\n",
    "    :returns: returns the method with its special tokens replaced\n",
    "    \"\"\"\n",
    "    # construct escaped versions of keys for running through regex\n",
    "    spec_toks = dict((re.escape(v), k) for k, v in sorted(java_special_tokens.items(), key = lambda x: len(x[1]), reverse = True))\n",
    "    # construct regex pattern for finding all special tokens in a method\n",
    "    pattern = re.compile(\"|\".join(spec_toks.keys()))\n",
    "    # replace all special tokens in a method\n",
    "    mthd = pattern.sub(lambda m: spec_toks[re.escape(m.group(0))], mthd)\n",
    "\n",
    "    return mthd\n",
    "\n",
    "def replace_special_tokens(df: pd.DataFrame, spec_toks: Dict[str, str], n: Optional[int] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Replace all the special tokens in a pandas dataframe.\n",
    "\n",
    "    :param df: the pandas dataframe containing each method to replace special tokens in\n",
    "    :param n: the number of methods to evaluate. If none, the entire dataframe will be used\n",
    "    :returns: returns a modified dataframe with the special tokens replaced\n",
    "    \"\"\"\n",
    "    if n is None: n = len(df)\n",
    "\n",
    "    df = df.iloc[:n].copy()\n",
    "    df.code = df.code.apply(lambda mthd: _replace_toks(mthd, spec_toks))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACED_MTHD = '<triple_greater> <greater> <+> <public> <++> <n><n> \\t \\t \\t\\t  '\n",
    "df_replaced = replace_special_tokens(df_fake, java_special_tokens)\n",
    "\n",
    "assert REPLACED_MTHD == df_replaced.code.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'>>> > + public ++ \\n\\n \\t \\t \\t\\t  '"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_replaced.code.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "df_replaced = replace_special_tokens(df_trn, java_special_tokens)\n",
    "print(df_replaced.code.values[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "fake_data = '<triple_greater> <greater> <+> <public> <++> <n><n>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def train_tokenizer(df: pd.DataFrame, n: Optional[int] = None, vocab_sz: Optional[int] = 10_000, min_freq: Optional[int] = 2, output: Optional[Path] = None) -> Tokenizer:\n",
    "    \"\"\"\n",
    "    Train a ByteLevel BPE tokenizer on a given pandas dataframe. Code adapted from https://github.com/huggingface/tokenizers/tree/master/bindings/python.\n",
    "\n",
    "    :param df: the pandas dataframe containing each method to have the tokenizer train on\n",
    "    :param n: the number of methods to evaluate. If none, the entire dataframe will be used\n",
    "    :param vocab_sz: the maximum vocabulary size of the trained tokenizer. Defaulted was selected from: Big Code != Big Vocabulary: Open-Vocabulary Models for Source Code\n",
    "    :param min_freq: the minimum frequency a token has to occur to be considered\n",
    "    :returns: returns a trained ByteLevel BPE tokenizer\n",
    "    \"\"\"\n",
    "    if n is None: n = len(df)\n",
    "\n",
    "    # create tmp file to store df contents for training tokenizer\n",
    "    tmp_path = Path('/tmp')\n",
    "    tmp_path.mkdir(parents = True, exist_ok = True)\n",
    "    with open(tmp_path/'tmp_tokenize.txt', 'w') as f:\n",
    "        f.write('\\n'.join(df.code.values[:n]))\n",
    "\n",
    "    # initialize a tokenizer\n",
    "    tokenizer = Tokenizer(models.BPE())\n",
    "\n",
    "    # customize pre-tokenization and decoding\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space = True)\n",
    "    tokenizer.decoder = decoders.ByteLevel()\n",
    "    tokenizer.post_processor = processors.ByteLevel(trim_offsets = True)\n",
    "\n",
    "    # train tokenizer with data in tmp file\n",
    "    trainer = trainers.BpeTrainer(\n",
    "        vocab_size = vocab_sz, min_frequency = min_freq,\n",
    "        special_tokens = list(java_special_tokens.keys())\n",
    "    )\n",
    "    tokenizer.train(trainer, [str(tmp_path/'tmp_tokenize.txt')])\n",
    "\n",
    "    # save tokenizer if output path given\n",
    "    if output is not None:\n",
    "        tokenizer.save(output, pretty = True)\n",
    "    \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZED_SPEC = [\n",
    "    '<triple_greater>', 'Ġ', '<greater>', 'Ġ', '<+>', 'Ġ',\n",
    "    '<public>', 'Ġ', '<++>', 'Ġ', '<n>', '<n>'\n",
    "]\n",
    "tokenizer = train_tokenizer(df_fake)\n",
    "encoded = tokenizer.encode(fake_data)\n",
    "\n",
    "assert TOKENIZED_SPEC == encoded.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "# idx = 0\n",
    "# df_beaut = beautify_code(df_trn, n = 10)\n",
    "# df_replaced = replace_special_tokens(df_beaut, java_special_tokens)\n",
    "\n",
    "# tokenizer = train_tokenizer(df_trn)\n",
    "# encoded = tokenizer.encode(df_replaced.code.values[idx])\n",
    "# print(df_replaced.code.values[idx])\n",
    "# print('=' * 100)\n",
    "# print(encoded.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
