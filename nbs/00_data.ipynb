{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "> This model contains all the necessary functionality for managing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import icodegen\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "from subprocess import check_output\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers, processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code</th>\n      <th>docstring</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>609</th>\n      <td>public ServiceFuture&lt;BackupStorageResult&gt; back...</td>\n      <td>Backs up the specified storage account.\\nReque...</td>\n    </tr>\n    <tr>\n      <th>15003</th>\n      <td>public static Type getPropertyType(Class&lt;?&gt; be...</td>\n      <td>Similar to {@link PropertyUtils#getPropertyCla...</td>\n    </tr>\n    <tr>\n      <th>15041</th>\n      <td>@Nullable\\n  public IUser getUserOfLoginName (...</td>\n      <td>Get the user with the specified login name\\n\\n...</td>\n    </tr>\n    <tr>\n      <th>2340</th>\n      <td>public boolean add(E e) {\\r\\n\\t\\thashCodeUpToD...</td>\n      <td>Appends the specified element to the end of th...</td>\n    </tr>\n    <tr>\n      <th>29660</th>\n      <td>@Override\\n    public PutPlaybackConfiguration...</td>\n      <td>&lt;p&gt;\\nAdds a new playback configuration to AWS ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                    code  \\\n609    public ServiceFuture&lt;BackupStorageResult&gt; back...   \n15003  public static Type getPropertyType(Class&lt;?&gt; be...   \n15041  @Nullable\\n  public IUser getUserOfLoginName (...   \n2340   public boolean add(E e) {\\r\\n\\t\\thashCodeUpToD...   \n29660  @Override\\n    public PutPlaybackConfiguration...   \n\n                                               docstring  \n609    Backs up the specified storage account.\\nReque...  \n15003  Similar to {@link PropertyUtils#getPropertyCla...  \n15041  Get the user with the specified login name\\n\\n...  \n2340   Appends the specified element to the end of th...  \n29660  &lt;p&gt;\\nAdds a new playback configuration to AWS ...  "
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "from ds4se.mgmnt.prep.i import jsonl_list_to_dataframe, get_dfs\n",
    "\n",
    "path = Path('/home/nathan/Downloads/')\n",
    "df_trn, df_val, df_tst = get_dfs(path/\"java/final/jsonl\")\n",
    "\n",
    "sample = 0.01\n",
    "df_trn = df_trn.sample(frac = sample)\n",
    "df_val = df_val.sample(frac = sample)\n",
    "df_tst = df_tst.sample(frac = sample)\n",
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(4545, 153, 269)"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "len(df_trn), len(df_val), len(df_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncrustify failure case. Will need to look into finding how many failure cases uncrustify generates.\n",
    "\n",
    "Original:\n",
    "```\n",
    "@Override\n",
    "    public WSStats[] getStatsArray(StatDescriptor[] sd, Boolean recursive) {\n",
    "        if (tc.isEntryEnabled())\n",
    "            Tr.entry(tc, \"getStatsArray (StatDescriptor[], Boolean)\");\n",
    "\n",
    "        if (sd == null || sd.length == 0) {\n",
    "            if (tc.isEntryEnabled())\n",
    "                Tr.exit(tc, \"StatDescriptor is null or empty\");\n",
    "            return null;\n",
    "        }\n",
    "\n",
    "        StatsImpl[] stats = PmiRegistry.getStats(sd, recursive.booleanValue(), new PmiModuleConfig(null));\n",
    "\n",
    "        if (tc.isEntryEnabled())\n",
    "            Tr.exit(tc, \"getStatsArray (StatDescriptor[], Boolean)\");\n",
    "\n",
    "        return stats;\n",
    "    }\n",
    "```\n",
    "\n",
    "Beautified:\n",
    "```\n",
    "@Override public WSStats[] getStatsArray(StatDescriptor[] sd, Boolean\n",
    "    recursive) {\n",
    "    if (tc.isEntryEnabled())\n",
    "\tTr.entry(tc, \"getStatsArray (StatDescriptor[], Boolean)\");\n",
    "    if (sd == null || sd.length == 0) {\n",
    "\tif (tc.isEntryEnabled())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>public void setPipelines(java.util.Collection&lt;...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                code\n0  public void setPipelines(java.util.Collection&lt;..."
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_fake = pd.DataFrame([\n",
    "    '''public void setPipelines(java.util.Collection<Pipeline> pipelines) {\n",
    "        if (pipelines == null) {\n",
    "            this.pipelines = null;\n",
    "            return;\n",
    "        }\n",
    "\n",
    "        this.pipelines = new com.amazonaws.internal.SdkInternalList<Pipeline>(pipelines);\n",
    "    }\n",
    "    '''\n",
    "], columns = ['code']); df_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _beautify(mthd):\n",
    "    # get path of icodegen\n",
    "    icodegen_path = Path(icodegen.__path__[0])\n",
    "\n",
    "    # create tmp file to store df contents for training tokenizer\n",
    "    tmp_path = Path('/tmp')\n",
    "    tmp_path.mkdir(parents = True, exist_ok = True)\n",
    "    with open(tmp_path/'tmp.java', 'w') as f:\n",
    "        f.write(mthd)\n",
    "\n",
    "    beaut_mthd = check_output([\n",
    "        icodegen_path/'uncrustify', '-c', icodegen_path/'sun.cfg',\n",
    "        '-f', tmp_path/'tmp.java'\n",
    "    ]).decode('utf-8')\n",
    "\n",
    "    return beaut_mthd\n",
    "\n",
    "# TODO: fix bugs that cause to crash/hang on certain inputs\n",
    "def beautify_code(df, n = None):\n",
    "    \"\"\"\n",
    "    Beautify the methods in a pandas dataframe using uncrustify with sun.cfg style, i.e., Oracle's style.\n",
    "\n",
    "    :param df: the pandas dataframe containing each method to be beautified\n",
    "    :param n: the number of methods to evaluate. If none, the entire dataframe will be used\n",
    "    :returns: returns a modified dataframe with the methods beautified\n",
    "    \"\"\"\n",
    "    if n is None: n = len(df)\n",
    "\n",
    "    df = df.iloc[:n].copy()\n",
    "    df.code = df.code.apply(lambda mthd: _beautify(mthd))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEAUT_MTHD = '''public void setPipelines(java.util.Collection<Pipeline> pipelines) {\n",
    "    if (pipelines == null) {\n",
    "\tthis.pipelines = null;\n",
    "\treturn;\n",
    "    }\n",
    "    this.pipelines = new com.amazonaws.internal.SdkInternalList<Pipeline>(\n",
    "\tpipelines);\n",
    "}\n",
    "'''\n",
    "\n",
    "df_beaut = beautify_code(df_fake)\n",
    "\n",
    "assert BEAUT_MTHD == df_beaut.code.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "CPU times: user 9.97 ms, sys: 116 ms, total: 126 ms\nWall time: 326 ms\n"
    }
   ],
   "source": [
    "# hide\n",
    "%%time\n",
    "df_beaut = beautify_code(df_trn, n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "public ServiceFuture&lt;BackupStorageResult&gt; backupStorageAccountAsync(String vaultBaseUrl, String storageAccountName, final ServiceCallback&lt;BackupStorageResult&gt; serviceCallback) {\n        return ServiceFuture.fromResponse(backupStorageAccountWithServiceResponseAsync(vaultBaseUrl, storageAccountName), serviceCallback);\n    }\npublic ServiceFuture&lt;BackupStorageResult&gt; backupStorageAccountAsync(String\n    vaultBaseUrl, String storageAccountName, final\n    ServiceCallback&lt;BackupStorageResult&gt; serviceCallback) {\n    return ServiceFuture.fromResponse(\n\tbackupStorageAccountWithServiceResponseAsync(vaultBaseUrl,\n\tstorageAccountName), serviceCallback);\n}\n\n"
    }
   ],
   "source": [
    "# hide\n",
    "idx = 0\n",
    "print(df_trn.code.values[idx])\n",
    "print(df_beaut.code.values[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# dicts of special tokens we are adding to the tokenizers so they do not get split\n",
    "\n",
    "# from https://docs.oracle.com/javase/tutorial/java/nutsandbolts/_keywords.html\n",
    "java_reserved_tokens = {\n",
    "    'abstract': '<abstract>', 'assert': '<assert>', 'boolean': '<boolean>',\n",
    "    'break': '<break>', 'byte': '<byte>', 'case': '<case>',\n",
    "    'catch': '<catch>', 'char': '<char>', 'class': '<class>',\n",
    "    'const': '<const>', 'continue': '<continue>', 'default': '<default>',\n",
    "    'do': '<do>', 'double': '<double>', 'else': '<else>',\n",
    "    'enum': '<enum>', 'extends': '<extends>', 'final': '<final>',\n",
    "    'finally': '<finally>', 'float': '<float>', 'for': '<for>',\n",
    "    'goto': '<goto>', 'if': '<if>', 'implements': '<implements>',\n",
    "    'import': '<import>', 'instanceof': '<instanceof>', 'int': '<int>',\n",
    "    'interface': '<interface>', 'long': '<long>', 'native': '<native>',\n",
    "    'new': '<new>', 'package': '<package>', 'private': '<private>',\n",
    "    'protected': '<protected>', 'public': '<public>', 'return': '<return>',\n",
    "    'short': '<short>', 'static': '<static>', 'strictfp': '<strictfp>',\n",
    "    'super': '<super>', 'switch': '<switch>', 'synchronized': '<synchronized>',\n",
    "    'this': '<this>', 'throw': '<throw>', 'throws': '<throws>',\n",
    "    'transient': '<transient>', 'try': '<try>', 'void': '<void>',\n",
    "    'volatile': '<volatile>', 'while': '<while>'\n",
    "}\n",
    "\n",
    "# from https://docs.oracle.com/javase/tutorial/java/nutsandbolts/opsummary.html\n",
    "java_operator_tokens = {\n",
    "    '=': '<=>', '+': '<+>', '-': '<->',\n",
    "    '*': '<*>', '/': '</>', '%': '<%>',\n",
    "    '++': '<++>', '--': '<-->', '!': '<!>',\n",
    "    '==': '<==>', '!=': '<!=>', '>': '<greater>',\n",
    "    '>=': '<greater_equal>', '<': '<lesser>', '<=': '<lesser_equal>',\n",
    "    '&&': '<&&>', '||': '<||>', '?': '<?>',\n",
    "    ':': '<:>', '~': '<~>', '<<': '<double_lesser>',\n",
    "    '>>': '<double_greater>', '>>>': '<triple_greater>', '&': '<&>',\n",
    "    '^': '<^>', '|': '<|>'\n",
    "}\n",
    "\n",
    "java_structural_tokens = {\n",
    "    '{': '<{>', '}': '<}>', '[': '<[>',\n",
    "    ']': '<]>', '<': '<lesser>', '>': '<greater>',\n",
    "    '(': '<(>', ')': '<)>', ';': '<;>'\n",
    "}\n",
    "\n",
    "java_extra_tokens = {\n",
    "    '@': '<@>', '...': '<...>'\n",
    "}\n",
    "\n",
    "# combination of all dictionaries\n",
    "java_special_tokens = {\n",
    "    **java_reserved_tokens, **java_operator_tokens,\n",
    "    **java_structural_tokens, **java_extra_tokens\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&gt;&gt;&gt; &gt; + public ++</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                code\n0  &gt;&gt;&gt; &gt; + public ++"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake = pd.DataFrame(['>>> > + public ++'], columns = ['code']); df_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _replace_toks(mthd, spec_toks):\n",
    "    \"\"\"\n",
    "    Helper function for replacing all special tokens in a given method. This will replace longer special tokens first in order to not mistakenly breakup a special token that is part of a longer sequence. Adapted from https://stackoverflow.com/a/6117124/5768407 and https://stackoverflow.com/a/11753945/5768407\n",
    "\n",
    "    :param mthd: the method to have it's special tokens replaced\n",
    "    :param spec_toks: a dictionary containing the special tokens to replace and the new tokens to replace them with\n",
    "    :returns: returns the method with all of its special tokens replaced\n",
    "    \"\"\"\n",
    "    # construct escaped versions of keys for running through regex\n",
    "    spec_toks = dict((re.escape(k), spec_toks[k]) for k in sorted(spec_toks, key=len, reverse=True))\n",
    "    # construct regex pattern for finding all special tokens in a method\n",
    "    pattern = re.compile(\"|\".join(spec_toks.keys()))\n",
    "    # replace all special tokens in a method\n",
    "    mthd = pattern.sub(lambda m: spec_toks[re.escape(m.group(0))], mthd)\n",
    "\n",
    "    return mthd\n",
    "\n",
    "def replace_special_tokens(df, spec_toks, n = None):\n",
    "    \"\"\"\n",
    "    Replace all the special tokens in a pandas dataframe.\n",
    "\n",
    "    :param df: the pandas dataframe containing each method to replace special tokens in\n",
    "    :param n: the number of methods to evaluate. If none, the entire dataframe will be used\n",
    "    :returns: returns a modified dataframe with the special tokens replaced\n",
    "    \"\"\"\n",
    "    if n is None: n = len(df)\n",
    "\n",
    "    df = df.iloc[:n].copy()\n",
    "    df.code = df.code.apply(lambda mthd: _replace_toks(mthd, spec_toks))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACED_MTHD = '<triple_greater> <greater> <+> <public> <++>'\n",
    "df_replaced = replace_special_tokens(df_fake, java_special_tokens)\n",
    "\n",
    "assert REPLACED_MTHD == df_replaced.code.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "&lt;public&gt; &lt;void&gt; setPipelines&lt;(&gt;java.util.Collection&lt;lesser&gt;Pipeline&lt;greater&gt; pipelines&lt;)&gt; &lt;{&gt;\n        &lt;if&gt; &lt;(&gt;pipelines &lt;==&gt; null&lt;)&gt; &lt;{&gt;\n            &lt;this&gt;.pipelines &lt;=&gt; null&lt;;&gt;\n            &lt;return&gt;&lt;;&gt;\n        &lt;}&gt;\n\n        &lt;this&gt;.pipelines &lt;=&gt; &lt;new&gt; com.amazonaws.&lt;int&gt;ernal.SdkInternalList&lt;lesser&gt;Pipeline&lt;greater&gt;&lt;(&gt;pipelines&lt;)&gt;&lt;;&gt;\n    &lt;}&gt;\n"
    }
   ],
   "source": [
    "# hide\n",
    "df_replaced = replace_special_tokens(df_trn, java_special_tokens)\n",
    "print(df_replaced.code.values[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# TODO: test case\n",
    "def train_tokenizer(df, n = None, vocab_sz = 20_000, min_freq = 2, output = None):\n",
    "    \"\"\"\n",
    "    Train a ByteLevel BPE tokenizer on a given pandas dataframe. Code adapted from https://github.com/huggingface/tokenizers/tree/master/bindings/python.\n",
    "\n",
    "    :param df: the pandas dataframe containing each method to have the tokenizer train on\n",
    "    :param n: the number of methods to evaluate. If none, the entire dataframe will be used\n",
    "    :param vocab_sz: the maximum vocabulary size of the trained tokenizer\n",
    "    :param min_freq: the minimum frequency a token has to occur to be considered\n",
    "    :returns: returns a trained ByteLevel BPE tokenizer\n",
    "    \"\"\"\n",
    "    if n is None: n = len(df)\n",
    "\n",
    "    # create tmp file to store df contents for training tokenizer\n",
    "    tmp_path = Path('/tmp')\n",
    "    tmp_path.mkdir(parents = True, exist_ok = True)\n",
    "    with open(tmp_path/'tmp_tokenize.txt', 'w') as f:\n",
    "        f.write('\\n'.join(df.code.values[:n]))\n",
    "\n",
    "    # initialize a tokenizer\n",
    "    tokenizer = Tokenizer(models.BPE())\n",
    "\n",
    "    # customize pre-tokenization and decoding\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space = True)\n",
    "    tokenizer.decoder = decoders.ByteLevel()\n",
    "    tokenizer.post_processor = processors.ByteLevel(trim_offsets = True)\n",
    "\n",
    "    # train tokenizer with data in tmp file\n",
    "    trainer = trainers.BpeTrainer(\n",
    "        vocab_size = vocab_sz, min_frequency = min_freq,\n",
    "        special_tokens = list(java_special_tokens.values())\n",
    "    )\n",
    "    tokenizer.train(trainer, [str(tmp_path/'tmp_tokenize.txt')])\n",
    "\n",
    "    # save tokenizer if output path given\n",
    "    if output is not None:\n",
    "        tokenizer.save(output, pretty = True)\n",
    "    \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "tokenizer = train_tokenizer(df_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "&lt;public&gt; ServiceFuture&lt;lesser&gt;BackupStorageResult&lt;greater&gt; backupStorageAccountAsync&lt;(&gt;String\n    vaultBaseUrl, String storageAccountName, &lt;final&gt;\n    ServiceCallback&lt;lesser&gt;BackupStorageResult&lt;greater&gt; serviceCallback&lt;)&gt; &lt;{&gt;\n    &lt;return&gt; ServiceFuture.fromResponse&lt;(&gt;\n\tbackupStorageAccountWithServiceResponseAsync&lt;(&gt;vaultBaseUrl,\n\tstorageAccountName&lt;)&gt;, serviceCallback&lt;)&gt;&lt;;&gt;\n&lt;}&gt;\n\n====================================================================================================\n[&#39;&lt;public&gt;&#39;, &#39;ĠServiceFuture&#39;, &#39;&lt;lesser&gt;&#39;, &#39;ĠBackup&#39;, &#39;StorageResult&#39;, &#39;&lt;greater&gt;&#39;, &#39;Ġbackup&#39;, &#39;StorageAccount&#39;, &#39;Async&#39;, &#39;&lt;(&gt;&#39;, &#39;ĠString&#39;, &#39;Ċ&#39;, &#39;ĠĠĠ&#39;, &#39;ĠvaultBaseUrl&#39;, &#39;,&#39;, &#39;ĠString&#39;, &#39;ĠstorageAccountName&#39;, &#39;,&#39;, &#39;Ġ&#39;, &#39;&lt;final&gt;&#39;, &#39;ĠĊ&#39;, &#39;ĠĠĠ&#39;, &#39;ĠServiceCallback&#39;, &#39;&lt;lesser&gt;&#39;, &#39;ĠBackup&#39;, &#39;StorageResult&#39;, &#39;&lt;greater&gt;&#39;, &#39;ĠserviceCallback&#39;, &#39;&lt;)&gt;&#39;, &#39;Ġ&#39;, &#39;&lt;{&gt;&#39;, &#39;ĠĊ&#39;, &#39;ĠĠĠĠ&#39;, &#39;&lt;return&gt;&#39;, &#39;ĠServiceFuture&#39;, &#39;.&#39;, &#39;fromResponse&#39;, &#39;&lt;(&gt;&#39;, &#39;ĠĊ&#39;, &#39;ĉ&#39;, &#39;backup&#39;, &#39;StorageAccount&#39;, &#39;WithServiceResponseAsync&#39;, &#39;&lt;(&gt;&#39;, &#39;ĠvaultBaseUrl&#39;, &#39;,&#39;, &#39;Ċ&#39;, &#39;ĉ&#39;, &#39;storage&#39;, &#39;AccountName&#39;, &#39;&lt;)&gt;&#39;, &#39;Ġ,&#39;, &#39;ĠserviceCallback&#39;, &#39;&lt;)&gt;&#39;, &#39;&lt;;&gt;&#39;, &#39;ĠĊ&#39;, &#39;&lt;}&gt;&#39;, &#39;ĠĊ&#39;]\n"
    }
   ],
   "source": [
    "# hide\n",
    "idx = 0\n",
    "df_beaut = beautify_code(df_trn, n = 10)\n",
    "df_replaced = replace_special_tokens(df_beaut, java_special_tokens)\n",
    "encoded = tokenizer.encode(df_replaced.code.values[idx])\n",
    "print(df_replaced.code.values[idx])\n",
    "print('=' * 100)\n",
    "print(encoded.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icodegen",
   "language": "python",
   "name": "icodegen"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
