{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp evaluation.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from icodegen.data.transforms import (\n",
    "    code_token_randomizer,\n",
    "    line_randomizer,\n",
    "    java_comment_remover,\n",
    "    transform_df,\n",
    ")\n",
    "from icodegen.model.core import Model, RNNModel\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from typing import Dict, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at sshleifer/tiny-gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# Setting up testing data\n",
    "from transformers import GPT2TokenizerFast, TFGPT2LMHeadModel\n",
    "from icodegen.model.core import TransformerModel, RNNModel\n",
    "\n",
    "# Using tiny-gpt2 for just quick tests since it is... tiny :)\n",
    "trnsfr_tokenizer = GPT2TokenizerFast.from_pretrained(\"sshleifer/tiny-gpt2\")\n",
    "tokenizer = trnsfr_tokenizer.backend_tokenizer\n",
    "trnsfr = TFGPT2LMHeadModel.from_pretrained(\"sshleifer/tiny-gpt2\")\n",
    "trnsfr_model = TransformerModel(tokenizer, trnsfr)\n",
    "\n",
    "rnn_type = \"gru\"\n",
    "n_layers = 1\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "embedding_dim = 128\n",
    "rnn_units = 128\n",
    "batch_size = 1\n",
    "out_path = \"/tmp\"\n",
    "gru_model = RNNModel(\n",
    "    rnn_type,\n",
    "    n_layers,\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    rnn_units,\n",
    "    batch_size,\n",
    "    out_path,\n",
    "    tokenizer,\n",
    ")\n",
    "\n",
    "df_fake = pd.DataFrame(\n",
    "    [\"aaaa(bb(aaaa(bb()()ccc)dd)()ccc)dd\", \"aaaa(bb()ccccc)dd\"], columns=[\"code\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaa(bb(aaaa(bb()()ccc)dd)()ccc)dd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaaa(bb()ccccc)dd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 code\n",
       "0  aaaa(bb(aaaa(bb()()ccc)dd)()ccc)dd\n",
       "1                   aaaa(bb()ccccc)dd"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_mean_probs(df: pd.DataFrame, model: Model, n: Optional[int] = None):\n",
    "    \"\"\"\n",
    "    Get the mean probability of each token that the model\n",
    "    should predict for an entire pandas dataframe.\n",
    "\n",
    "    :param df: the pandas dataframe containing each method to have the model predict on\n",
    "    :param model: the model used to generate the predictions\n",
    "    :param n: the number of methods to evaluate. If none, the entire dataframe will be used\n",
    "    :returns: returns a numpy array of the mean probability for each token in the model's vocab\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        n = len(df)\n",
    "\n",
    "    # setup container lists for the number of occurrences and sum of probabilities for each token\n",
    "    counts = [0] * model.tokenizer.get_vocab_size()\n",
    "    sum_probs = [0.0] * model.tokenizer.get_vocab_size()\n",
    "    # loop through each method\n",
    "    for mthd in df.code.values[:n]:\n",
    "        # token the method and generate the probabilities for the model's predictions\n",
    "        inputs = model.tokenize(mthd)\n",
    "        probs = model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "        # loop through each token and its probability and update the container lists\n",
    "        for idx, p in zip(inputs[\"input_ids\"][0], probs):\n",
    "            counts[idx] += 1\n",
    "            sum_probs[idx] += p[idx]\n",
    "\n",
    "    # convert the lists to numpy lists and perform element wise division to get the mean probabilities for each token\n",
    "    counts = np.array(counts)\n",
    "    sum_probs = np.array(sum_probs)\n",
    "\n",
    "    # perform division, but not when denominator is zero. In those cases, just leave value as NAN.\n",
    "    nans = np.empty(counts.shape)\n",
    "    nans.fill(np.nan)\n",
    "    mean_probs = np.divide(sum_probs, counts, out=nans, where=counts != 0)\n",
    "    # TODO: convert to dictionary with keys as tokens\n",
    "    mean_probs = {\n",
    "        model.tokenizer.id_to_token(i): mean_probs[i] for i in range(len(mean_probs))\n",
    "    }\n",
    "    return mean_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_NAN_PROBS_MEAN = np.array(\n",
    "    [\n",
    "        2.01237513e-05,\n",
    "        1.98944481e-05,\n",
    "        2.01449202e-05,\n",
    "        2.04353437e-05,\n",
    "        2.02043060e-05,\n",
    "        2.02826177e-05,\n",
    "        2.09888076e-05,\n",
    "        2.07051467e-05,\n",
    "        1.98100976e-05,\n",
    "        2.02152678e-05,\n",
    "        2.02035244e-05,\n",
    "        2.10283021e-05,\n",
    "    ]\n",
    ")\n",
    "\n",
    "mean_probs = np.array(list(get_mean_probs(df_fake, trnsfr_model).values()))\n",
    "non_nan_idx = np.argwhere(~np.isnan(mean_probs)).flatten()\n",
    "non_nan_mean_prob = mean_probs[non_nan_idx]\n",
    "\n",
    "assert np.isclose(non_nan_mean_prob, NON_NAN_PROBS_MEAN, atol=1.0e-6).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_NAN_PROBS_MEAN = np.array(\n",
    "    [\n",
    "        1.99270412e-05,\n",
    "        1.99168703e-05,\n",
    "        1.98815596e-05,\n",
    "        1.99057849e-05,\n",
    "        1.98800869e-05,\n",
    "        1.98893995e-05,\n",
    "        1.98797388e-05,\n",
    "        1.98960342e-05,\n",
    "        1.99086674e-05,\n",
    "        1.98605580e-05,\n",
    "        1.98807957e-05,\n",
    "        1.98842057e-05,\n",
    "    ]\n",
    ")\n",
    "\n",
    "mean_probs = np.array(list(get_mean_probs(df_fake, gru_model).values()))\n",
    "non_nan_idx = np.argwhere(~np.isnan(mean_probs)).flatten()\n",
    "non_nan_mean_prob = mean_probs[non_nan_idx]\n",
    "\n",
    "assert np.isclose(non_nan_mean_prob, NON_NAN_PROBS_MEAN, atol=1.0e-6).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def find_parens(toks: List[str], opening: str, closing: str) -> Dict[int, int]:\n",
    "    \"\"\"\n",
    "    Get the indices for the opening and closing tokens.\n",
    "    From https://stackoverflow.com/a/29992065/5768407\n",
    "    by user Baltasarq (https://stackoverflow.com/users/266978/baltasarq).\n",
    "\n",
    "    :param toks: the tokenized version of a method\n",
    "    :param opening: the opening token that will be matched against the closing token\n",
    "    :param closing: the closing token that will be matched against the opening token\n",
    "    :returns: returns a dictionary with the opening token indices as the keys and the closing token indices as the values\n",
    "    \"\"\"\n",
    "    toret = {}\n",
    "    pstack = []\n",
    "\n",
    "    for i, tok in enumerate(toks):\n",
    "        if tok == opening:\n",
    "            pstack.append(i)\n",
    "        elif tok == closing:\n",
    "            if len(pstack) == 0:\n",
    "                raise IndexError(\"No matching closing parens at: \" + str(i))\n",
    "            toret[pstack.pop()] = i\n",
    "\n",
    "    if len(pstack) > 0:\n",
    "        raise IndexError(\"No matching opening parens at: \" + str(pstack.pop()))\n",
    "\n",
    "    return toret\n",
    "\n",
    "\n",
    "def _get_dist_probs(\n",
    "    mthd: str, model: Model, opening: str, closing: str\n",
    ") -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Get the distances and mean probabilities between opening and closing tokens in a given method.\n",
    "\n",
    "    :param mthd: the method to get the ranges of the opening and closing tokens and their probabilities\n",
    "    :param model: the model used to generate the predictions\n",
    "    :param opening: the opening token used for calculating the distance between opening and closing tokens\n",
    "    :param closing: the closing token used for calculating the distance between opening and closing tokens as well as the token to get the mean probability of\n",
    "    :returns: returns a dictionary with the distance between the opening and closing tokens as keys and their mean probabilities as values\n",
    "    \"\"\"\n",
    "    # WARNING: Careful when using different tokenizers since HF tokenizers lib have diff API then HF transformers lib tokenizers... You will need to update this when using custom model and tokenizer...\n",
    "\n",
    "    # get the distances for the opening and closing tokens\n",
    "    toks = model.tokenizer.encode(mthd).tokens\n",
    "    idxs = find_parens(toks, opening, closing)\n",
    "\n",
    "    # get the model probabilities for the given method\n",
    "    inputs = model.tokenize(mthd)\n",
    "    probs = model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "    # sum up the probabilities of the different distances for the closing token\n",
    "    dist_probs = defaultdict(float)\n",
    "    for open_id, close_id in idxs.items():\n",
    "        dist_probs[close_id - open_id] += probs[close_id][\n",
    "            inputs[\"input_ids\"][0][close_id]\n",
    "        ]\n",
    "\n",
    "    # get the mean of the summed probabilities\n",
    "    dist_cnts = Counter([close_id - open_id for open_id, close_id in idxs.items()])\n",
    "    dist_probs = {dist: dist_probs[dist] / n for dist, n in dist_cnts.items()}\n",
    "    return dist_probs\n",
    "\n",
    "\n",
    "def mean_dist_probs(\n",
    "    df: pd.DataFrame,\n",
    "    model: Model,\n",
    "    opening: Optional[str] = \"<{>\",\n",
    "    closing: Optional[str] = \"<}>\",\n",
    "    n: Optional[int] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get the distance between opening and closing tokens and the mean probability of each closing token that the model should predict for an entire pandas dataframe.\n",
    "\n",
    "    :param df: the pandas dataframe containing each method to have the model predict on\n",
    "    :param model: the model used to generate the predictions\n",
    "    :param opening: the opening token used for calculating the distance between opening and closing tokens\n",
    "    :param closing: the closing token used for calculating the distance between opening and closing tokens as well as the token to get the mean probability of\n",
    "    :param n: the number of methods to evaluate. If none, the entire dataframe will be used\n",
    "    :returns: returns a dataframe with the distances between opening and closing tokens and their mean probabilities\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        n = len(df)\n",
    "\n",
    "    # get the probabilities for the different distances for an entire dataframe\n",
    "    df = df.iloc[:n].copy()\n",
    "    dist_probs = df.code.apply(\n",
    "        lambda mthd: _get_dist_probs(mthd, model, opening, closing)\n",
    "    ).values\n",
    "\n",
    "    # flatten the keys of the different distances into a list\n",
    "    dist_keys = []\n",
    "    for probs in dist_probs:\n",
    "        dist_keys.extend(probs.keys())\n",
    "    # merge dictionaries across methods by taking the mean of probs with the same distance. Modified from https://stackoverflow.com/a/10461916/5768407,\n",
    "    # users georg https://stackoverflow.com/users/989121/georg and Rémy Hosseinkhan Boucher https://stackoverflow.com/users/12149730/r%c3%a9my-hosseinkhan-boucher\n",
    "    mean_dist_probs = {\n",
    "        k: np.nanmean(np.array([probs.get(k, np.nan) for probs in dist_probs]))\n",
    "        for k in set(dist_keys)\n",
    "    }\n",
    "    std_dist_probs = {\n",
    "        k: np.nanstd(np.array([probs.get(k, np.nan) for probs in dist_probs]))\n",
    "        for k in set(dist_keys)\n",
    "    }\n",
    "\n",
    "    med_dist_probs = {\n",
    "        k: np.nanmedian(np.array([probs.get(k, np.nan) for probs in dist_probs]))\n",
    "        for k in set(dist_keys)\n",
    "    }\n",
    "    mad_dist_probs = {\n",
    "        k: stats.median_abs_deviation(\n",
    "            np.array([probs.get(k, np.nan) for probs in dist_probs]), nan_policy=\"omit\"\n",
    "        )\n",
    "        for k in set(dist_keys)\n",
    "    }\n",
    "    # TODO: convert to dictionary\n",
    "    df_dist = (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"dist\": list(mean_dist_probs.keys()),\n",
    "                \"mean_prob\": list(mean_dist_probs.values()),\n",
    "                \"std_prob\": list(std_dist_probs.values()),\n",
    "                \"med_prob\": list(med_dist_probs.values()),\n",
    "                \"mad_prob\": list(mad_dist_probs.values()),\n",
    "            }\n",
    "        )\n",
    "        .sort_values(\"dist\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return df_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIST_DF = pd.DataFrame(\n",
    "    {\n",
    "        \"dist\": [6, 10, 16],\n",
    "        \"mean_prob\": [\n",
    "            1.98822217e-05,\n",
    "            1.97613608e-05,\n",
    "            1.97816771e-05,\n",
    "        ],\n",
    "        \"std_prob\": [\n",
    "            4.93400876e-09,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "        ],\n",
    "        \"med_prob\": [\n",
    "            2.04683793e-05,\n",
    "            2.07205376e-05,\n",
    "            1.97817026e-05,\n",
    "        ],\n",
    "        \"mad_prob\": [\n",
    "            4.93400876e-09,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "df_dist = mean_dist_probs(df_fake, gru_model, opening=\"(\", closing=\")\")\n",
    "\n",
    "assert (DIST_DF.dist.values == df_dist.dist.values).all()\n",
    "assert np.isclose(DIST_DF.mean_prob.values, df_dist.mean_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.std_prob.values, df_dist.std_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.med_prob.values, df_dist.med_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.mad_prob.values, df_dist.mad_prob.values, atol=1.0e-6).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIST_DF = pd.DataFrame(\n",
    "    {\n",
    "        \"dist\": [6, 10, 16],\n",
    "        \"mean_prob\": [\n",
    "            1.98822217e-05,\n",
    "            1.97613608e-05,\n",
    "            1.97816771e-05,\n",
    "        ],\n",
    "        \"std_prob\": [\n",
    "            4.93400876e-09,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "        ],\n",
    "        \"med_prob\": [\n",
    "            2.04683793e-05,\n",
    "            2.07205376e-05,\n",
    "            1.97817026e-05,\n",
    "        ],\n",
    "        \"mad_prob\": [\n",
    "            4.93400876e-09,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "df_dist = mean_dist_probs(df_fake, trnsfr_model, opening=\"(\", closing=\")\")\n",
    "\n",
    "assert (DIST_DF.dist.values == df_dist.dist.values).all()\n",
    "assert np.isclose(DIST_DF.mean_prob.values, df_dist.mean_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.std_prob.values, df_dist.std_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.med_prob.values, df_dist.med_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.mad_prob.values, df_dist.mad_prob.values, atol=1.0e-6).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "token_taxonomy = {\n",
    "  \"blocks\": {\n",
    "    \"<{>\": \"{\",\n",
    "    \"<}>\": \"}\",\n",
    "    \"<[>\": \"[\",\n",
    "    \"<]>\": \"]\",\n",
    "    \"<(>\": \"(\",\n",
    "    \"<)>\": \")\",\n",
    "    \"<;>\": \";\",\n",
    "    \"<return>\": \"return\"\n",
    "  },\n",
    "  \"exceptions\": {\n",
    "    \"<catch>\": \"catch\",\n",
    "    \"<try>\": \"try\",\n",
    "    \"<finally>\": \"finally\",\n",
    "    \"<throw>\": \"throw\",\n",
    "    \"<throws>\": \"throws\"\n",
    "  },\n",
    "  \"oop\": {\n",
    "    \"<class>\": \"class\",\n",
    "    \"<instanceof>\": \"instanceof\",\n",
    "    \"<interface>\": \"interface\",\n",
    "    \"<private>\": \"private\",\n",
    "    \"<protected>\": \"protected\",\n",
    "    \"<public>\": \"public\",\n",
    "    \"<abstract>\": \"abstract\",\n",
    "    \"<extends>\": \"extends\",\n",
    "    \"<package>\": \"package\",\n",
    "    \"<this>\": \"this\",\n",
    "    \"<implements>\": \"implements\",\n",
    "    \"<import>\": \"import\",\n",
    "    \"<new>\": \"new\",\n",
    "    \"<super>\": \"super\"\n",
    "  },\n",
    "  \"tests\": {\n",
    "    \"<assert>\": \"assert\"\n",
    "  },\n",
    "  \"declarations\": {\n",
    "    \"<native>\": \"native\",\n",
    "    \"<static>\": \"static\",\n",
    "    \"<synchronized>\": \"synchronized\",\n",
    "    \"<transient>\": \"transient\",\n",
    "    \"<volatile>\": \"volatile\",\n",
    "    \"<void>\": \"void\",\n",
    "    \"<final>\": \"final\",\n",
    "    \"<enum>\": \"enum\"\n",
    "  },\n",
    "  \"conditionals\": {\n",
    "    \"<else>\": \"else\",\n",
    "    \"<if>\": \"if\",\n",
    "    \"<switch>\": \"switch\",\n",
    "    \"<case>\": \"case\",\n",
    "    \"<default>\": \"default\"\n",
    "  },\n",
    "  \"loops\": {\n",
    "    \"<break>\": \"break\",\n",
    "    \"<do>\": \"do\",\n",
    "    \"<for>\": \"for\",\n",
    "    \"<while>\": \"while\",\n",
    "    \"<continue>\": \"continue\"\n",
    "  },\n",
    "  \"operators\": {\n",
    "    \"<=>\": \"=\",\n",
    "    \"<+>\": \"+\",\n",
    "    \"<->\": \"-\",\n",
    "    \"<*>\": \"*\",\n",
    "    \"</>\": \"/\",\n",
    "    \"<%>\": \"%\",\n",
    "    \"<++>\": \"++\",\n",
    "    \"<-->\": \"--\",\n",
    "    \"<!>\": \"!\",\n",
    "    \"<==>\": \"==\",\n",
    "    \"<!=>\": \"!=\",\n",
    "    \"<greater_equal>\": \">=\",\n",
    "    \"<lesser_equal>\": \"<=\",\n",
    "    \"<&&>\": \"&&\",\n",
    "    \"<||>\": \"||\",\n",
    "    \"<?>\": \"?\",\n",
    "    \"<:>\": \":\",\n",
    "    \"<~>\": \"~\",\n",
    "    \"<double_lesser>\": \"<<\",\n",
    "    \"<double_greater>\": \">>\",\n",
    "    \"<triple_greater>\": \">>>\",\n",
    "    \"<&>\": \"&\",\n",
    "    \"<^>\": \"^\",\n",
    "    \"<|>\": \"|\"\n",
    "  },\n",
    "  \"datatypes\": {\n",
    "    \"<byte>\": \"byte\",\n",
    "    \"<char>\": \"char\",\n",
    "    \"<float>\": \"float\",\n",
    "    \"<boolean>\": \"boolean\",\n",
    "    \"<double>\": \"double\",\n",
    "    \"<int>\": \"int\",\n",
    "    \"<long>\": \"long\",\n",
    "    \"<short>\": \"short\",\n",
    "    \"<strictfp>\": \"strictfp\"\n",
    "  },\n",
    "  \"extra_tokens\": {\n",
    "    \"<@>\": \"@\",\n",
    "    \"<...>\": \"...\",\n",
    "    \"<null>\": \"null\",\n",
    "    \"<true>\": \"true\",\n",
    "    \"<false>\": \"false\",\n",
    "    \"<n>\": \"\\n\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "ERROR_THRESHOLD = 0.5\n",
    "\n",
    "def get_error_rates(df: pd.DataFrame, model: Model, n: Optional[int] = None):\n",
    "    if n is None:\n",
    "        n = len(df)\n",
    "\n",
    "    # setup container lists for the number of occurrences and sum of probabilities for each token\n",
    "    cnts = [0] * model.tokenizer.get_vocab_size()\n",
    "    err_cnts = [0] * model.tokenizer.get_vocab_size()\n",
    "    # loop through each method\n",
    "    for mthd in df.code.values[:n]:\n",
    "        # token the method and generate the probabilities for the model's predictions\n",
    "        inputs = model.tokenize(mthd)\n",
    "        probs = model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "        # loop through each token and its probability and update the container lists\n",
    "        for idx, p in zip(inputs[\"input_ids\"][0], probs):\n",
    "            cnts[idx] += 1\n",
    "            if p[idx] < ERROR_THRESHOLD:\n",
    "                err_cnts[idx] += 1\n",
    "\n",
    "    # convert the lists to numpy lists and perform element wise division to get the mean probabilities for each token\n",
    "    cnts = np.array(cnts)\n",
    "    err_cnts = np.array(err_cnts)\n",
    "\n",
    "    # perform division, but not when denominator is zero. In those cases, just leave value as NAN.\n",
    "    nans = np.empty(cnts.shape)\n",
    "    nans.fill(np.nan)\n",
    "    mean_errs = np.divide(err_cnts, cnts, out=nans, where=cnts != 0)\n",
    "    \n",
    "    error_taxonomy = token_taxonomy.copy()\n",
    "    \n",
    "    for cat, tokens in error_taxonomy.items():\n",
    "        errs = []\n",
    "        cnt_sum = 0\n",
    "        for token, keyword in tokens.items():\n",
    "            idx = model.tokenizer.token_to_id(token)\n",
    "            error_taxonomy[cat][token] = {\"error_rate\": mean_errs[idx], \"count\": cnts[idx]}\n",
    "            errs.append(mean_errs[idx])\n",
    "            cnt_sum += cnts[idx]\n",
    "\n",
    "        errs = np.array(errs)\n",
    "        error_taxonomy[cat][\"stats\"] = {\n",
    "            \"mean_error_rate\": np.nanmean(errs),\n",
    "            \"stdev_error_rate\": np.nanstd(errs),\n",
    "            \"median_error_rate\": np.nanmedian(errs),\n",
    "            \"mad_error_rate\": stats.median_abs_deviation(errs, nan_policy=\"omit\"),\n",
    "        }\n",
    "    \n",
    "    return error_taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blocks': {'<{>': {'error_rate': 1.0, 'count': 27},\n",
       "  '<}>': {'error_rate': 1.0, 'count': 27},\n",
       "  '<[>': {'error_rate': 1.0, 'count': 3},\n",
       "  '<]>': {'error_rate': 1.0, 'count': 3},\n",
       "  '<(>': {'error_rate': 1.0, 'count': 81},\n",
       "  '<)>': {'error_rate': 0.8888888888888888, 'count': 81},\n",
       "  '<;>': {'error_rate': 1.0, 'count': 53},\n",
       "  '<return>': {'error_rate': 1.0, 'count': 10},\n",
       "  'stats': {'mean_error_rate': 0.9861111111111112,\n",
       "   'stdev_error_rate': 0.03674654598700822,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'exceptions': {'<catch>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<try>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<finally>': {'error_rate': nan, 'count': 0},\n",
       "  '<throw>': {'error_rate': nan, 'count': 0},\n",
       "  '<throws>': {'error_rate': 1.0, 'count': 1},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'oop': {'<class>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<instanceof>': {'error_rate': nan, 'count': 0},\n",
       "  '<interface>': {'error_rate': nan, 'count': 0},\n",
       "  '<private>': {'error_rate': 1.0, 'count': 3},\n",
       "  '<protected>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<public>': {'error_rate': 1.0, 'count': 5},\n",
       "  '<abstract>': {'error_rate': nan, 'count': 0},\n",
       "  '<extends>': {'error_rate': nan, 'count': 0},\n",
       "  '<package>': {'error_rate': nan, 'count': 0},\n",
       "  '<this>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<implements>': {'error_rate': nan, 'count': 0},\n",
       "  '<import>': {'error_rate': nan, 'count': 0},\n",
       "  '<new>': {'error_rate': 1.0, 'count': 6},\n",
       "  '<super>': {'error_rate': 1.0, 'count': 2},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'tests': {'<assert>': {'error_rate': 1.0, 'count': 2},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'declarations': {'<native>': {'error_rate': nan, 'count': 0},\n",
       "  '<static>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<synchronized>': {'error_rate': nan, 'count': 0},\n",
       "  '<transient>': {'error_rate': nan, 'count': 0},\n",
       "  '<volatile>': {'error_rate': nan, 'count': 0},\n",
       "  '<void>': {'error_rate': 1.0, 'count': 7},\n",
       "  '<final>': {'error_rate': nan, 'count': 0},\n",
       "  '<enum>': {'error_rate': nan, 'count': 0},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'conditionals': {'<else>': {'error_rate': 1.0, 'count': 4},\n",
       "  '<if>': {'error_rate': 1.0, 'count': 11},\n",
       "  '<switch>': {'error_rate': nan, 'count': 0},\n",
       "  '<case>': {'error_rate': nan, 'count': 0},\n",
       "  '<default>': {'error_rate': nan, 'count': 0},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'loops': {'<break>': {'error_rate': nan, 'count': 0},\n",
       "  '<do>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<for>': {'error_rate': 1.0, 'count': 4},\n",
       "  '<while>': {'error_rate': nan, 'count': 0},\n",
       "  '<continue>': {'error_rate': nan, 'count': 0},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'operators': {'<=>': {'error_rate': 1.0, 'count': 18},\n",
       "  '<+>': {'error_rate': 1.0, 'count': 3},\n",
       "  '<->': {'error_rate': 1.0, 'count': 2},\n",
       "  '<*>': {'error_rate': 1.0, 'count': 2},\n",
       "  '</>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<%>': {'error_rate': nan, 'count': 0},\n",
       "  '<++>': {'error_rate': nan, 'count': 0},\n",
       "  '<-->': {'error_rate': nan, 'count': 0},\n",
       "  '<!>': {'error_rate': 1.0, 'count': 5},\n",
       "  '<==>': {'error_rate': 1.0, 'count': 4},\n",
       "  '<!=>': {'error_rate': 1.0, 'count': 2},\n",
       "  '<greater_equal>': {'error_rate': nan, 'count': 0},\n",
       "  '<lesser_equal>': {'error_rate': nan, 'count': 0},\n",
       "  '<&&>': {'error_rate': nan, 'count': 0},\n",
       "  '<||>': {'error_rate': nan, 'count': 0},\n",
       "  '<?>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<:>': {'error_rate': 1.0, 'count': 4},\n",
       "  '<~>': {'error_rate': nan, 'count': 0},\n",
       "  '<double_lesser>': {'error_rate': nan, 'count': 0},\n",
       "  '<double_greater>': {'error_rate': nan, 'count': 0},\n",
       "  '<triple_greater>': {'error_rate': nan, 'count': 0},\n",
       "  '<&>': {'error_rate': nan, 'count': 0},\n",
       "  '<^>': {'error_rate': nan, 'count': 0},\n",
       "  '<|>': {'error_rate': nan, 'count': 0},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'datatypes': {'<byte>': {'error_rate': nan, 'count': 0},\n",
       "  '<char>': {'error_rate': nan, 'count': 0},\n",
       "  '<float>': {'error_rate': nan, 'count': 0},\n",
       "  '<boolean>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<double>': {'error_rate': nan, 'count': 0},\n",
       "  '<int>': {'error_rate': 1.0, 'count': 15},\n",
       "  '<long>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<short>': {'error_rate': nan, 'count': 0},\n",
       "  '<strictfp>': {'error_rate': nan, 'count': 0},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'extra_tokens': {'<@>': {'error_rate': 1.0, 'count': 4},\n",
       "  '<...>': {'error_rate': nan, 'count': 0},\n",
       "  '<null>': {'error_rate': 1.0, 'count': 2},\n",
       "  '<true>': {'error_rate': 1.0, 'count': 4},\n",
       "  '<false>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<n>': {'error_rate': 1.0, 'count': 98},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugfix_path = Path(\"/home/jovyan/work/dvc-icodegen/datasets/controlled/testbeds/_ts_bug_fix\")\n",
    "df_buggy = pd.read_json(bugfix_path / \"buggy.jsonl\", orient=\"records\", lines=True)[\n",
    "    :10\n",
    "]\n",
    "model = RNNModel.from_path(\"/home/jovyan/work/dvc-icodegen/models/gru_layers1_vocab10000_embed256_units512\")\n",
    "err_tax = get_error_rates(df_buggy, model)\n",
    "err_tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Need to move all these visualizations to their own module...\n",
    "# TODO: make this binning process easier where I can just pass in some vars and it handles it for me\n",
    "# df_dist[\"bin\"] = pd.cut(\n",
    "#     df_dist.dist, bins=[0, 10, 20], labels=[\"0-10\", \"11-20\"], include_lowest=True\n",
    "# )\n",
    "# df_dist = df_dist.sort_values(\"dist\")\n",
    "\n",
    "# bars = {}\n",
    "# for x in df_dist.bin.unique():\n",
    "#     bars[x] = sum(df_dist.loc[df_dist.bin == x].mean_prob.values)\n",
    "\n",
    "# plt.bar(bars.keys(), bars.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_mean_cross_entropy(df: pd.DataFrame, model: Model, n: Optional[int] = None):\n",
    "    \"\"\"\n",
    "    Get the mean cross entropy for a model on an entire pandas dataframe\n",
    "\n",
    "    :param df: the pandas dataframe containing each method to have the model predict on\n",
    "    :param model: the model used to generate the predictions\n",
    "    :param n: the number of methods to evaluate. If none, the entire dataframe will be used\n",
    "    :returns: returns the mean cross entropy of the models predictions compared to true labels\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        n = len(df)\n",
    "\n",
    "    cross_entropy_losses = []\n",
    "    # Need to change to sparse_categorical_crossentropy\n",
    "    for mthd in df.code.values[:n]:\n",
    "        # token the method and get the probabilities for each token from the model\n",
    "        inputs = model.tokenize(mthd)\n",
    "        probs = model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "        # calculate the cross entropy between the labels and probabilities\n",
    "        losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            inputs[\"input_ids\"], probs\n",
    "        ).numpy()\n",
    "        cross_entropy_losses.append(losses)\n",
    "\n",
    "    # flatten list of cross entropies and calculate the mean, median, std, and mad\n",
    "    cross_entropy_losses = np.concatenate(cross_entropy_losses)\n",
    "    return {\n",
    "        \"mean\": np.mean(cross_entropy_losses),\n",
    "        \"median\": np.median(cross_entropy_losses),\n",
    "        \"std\": np.std(cross_entropy_losses),\n",
    "        \"mad\": stats.median_abs_deviation(cross_entropy_losses),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_losses = []\n",
    "for mthd in df_fake.code.values:\n",
    "    inputs = gru_model.tokenize(mthd)\n",
    "    probs = gru_model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "    losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        inputs[\"input_ids\"], probs\n",
    "    ).numpy()\n",
    "    cross_entropy_losses.append(losses)\n",
    "\n",
    "CROSS_ENTROPY_MEAN = np.mean(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_MEDIAN = np.median(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_STD = np.std(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_MAD = stats.median_abs_deviation(np.concatenate(cross_entropy_losses))\n",
    "cross_entropy = get_mean_cross_entropy(df_fake, gru_model)\n",
    "\n",
    "assert np.isclose(CROSS_ENTROPY_MEAN, cross_entropy[\"mean\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_MEDIAN, cross_entropy[\"median\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_STD, cross_entropy[\"std\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_MAD, cross_entropy[\"mad\"], atol=1.0e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_losses = []\n",
    "for mthd in df_fake.code.values:\n",
    "    inputs = trnsfr_model.tokenize(mthd)\n",
    "    probs = trnsfr_model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "    losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        inputs[\"input_ids\"], probs\n",
    "    ).numpy()\n",
    "    cross_entropy_losses.append(losses)\n",
    "\n",
    "CROSS_ENTROPY_MEAN = np.mean(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_MEDIAN = np.median(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_STD = np.std(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_MAD = stats.median_abs_deviation(np.concatenate(cross_entropy_losses))\n",
    "cross_entropy = get_mean_cross_entropy(df_fake, trnsfr_model)\n",
    "\n",
    "assert np.isclose(CROSS_ENTROPY_MEAN, cross_entropy[\"mean\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_MEDIAN, cross_entropy[\"median\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_STD, cross_entropy[\"std\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_MAD, cross_entropy[\"mad\"], atol=1.0e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "_TRANSFORMs = {\n",
    "#     \"randomized_tokens\": code_token_randomizer,\n",
    "#     \"randomized_lines\": line_randomizer,\n",
    "    \"comments_removed\": java_comment_remover,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/dvc-icodegen/models/gru_layers1_vocab10000_embed256_units512\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "def _get_metrics(df, model):\n",
    "#     mean_probs = get_mean_probs(df, model)\n",
    "    error_taxonomy = get_error_rates(df, model)\n",
    "    df_dist = mean_dist_probs(df, model)\n",
    "    mean_cross_entropy = get_mean_cross_entropy(df, model)\n",
    "\n",
    "    return {\n",
    "        \"error_taxonomy\": error_taxonomy,\n",
    "        \"dist_mean\": df_dist,\n",
    "        \"mean_cross_entropy\": mean_cross_entropy,\n",
    "    }\n",
    "\n",
    "\n",
    "# def _long_range(data_dir, model, n=None):\n",
    "#     long_range_results = {}\n",
    "\n",
    "#     df_buggy = pd.read_json(data_dir / \"buggy.jsonl\", orient=\"records\", lines=True)[:n]\n",
    "#     long_range_results[\"buggy\"] = _get_metrics(df_buggy, model)\n",
    "#     del df_buggy\n",
    "\n",
    "#     df_fixed = pd.read_json(data_dir / \"fixed.jsonl\", orient=\"records\", lines=True)[:n]\n",
    "#     long_range_results[\"fixed\"] = _get_metrics(df_fixed, model)\n",
    "#     del df_fixed\n",
    "\n",
    "#     df_codesearchnet = pd.read_json(\n",
    "#         data_dir / \"codesearchnet_java\" / \"test.jsonl\", orient=\"records\", lines=True\n",
    "#     )[:n]\n",
    "#     long_range_results[\"codesearchnet_original\"] = _get_metrics(df_codesearchnet, model)\n",
    "\n",
    "#     for transform in _TRANSFORMs:\n",
    "#         df_transformed = transform_df(df_codesearchnet, _TRANSFORMs[transform])\n",
    "#         long_range_results[\"codesearchnet_\" + transform] = _get_metrics(\n",
    "#             df_transformed, model\n",
    "#         )\n",
    "#         del df_transformed\n",
    "\n",
    "#     return long_range_results\n",
    "\n",
    "\n",
    "def _long_range(bigclone_path, bugfix_path, codesearchnet_path, model, n=None):\n",
    "    long_range_results = {}\n",
    "\n",
    "    # TODO add bigclone data\n",
    "\n",
    "    df_buggy = pd.read_json(bugfix_path / \"buggy.jsonl\", orient=\"records\", lines=True)[\n",
    "        :n\n",
    "    ]\n",
    "    long_range_results[\"buggy\"] = _get_metrics(df_buggy, model)\n",
    "\n",
    "    df_fixed = pd.read_json(bugfix_path / \"fixed.jsonl\", orient=\"records\", lines=True)[\n",
    "        :n\n",
    "    ]\n",
    "    long_range_results[\"fixed\"] = _get_metrics(df_fixed, model)\n",
    "\n",
    "#     df_codesearchnet = pd.read_json(\n",
    "#         codesearchnet_path / \"codesearchnet_java\" / \"test.jsonl\",\n",
    "#         orient=\"records\",\n",
    "#         lines=True,\n",
    "#     )[:n]\n",
    "#     long_range_results[\"codesearchnet_original\"] = _get_metrics(df_codesearchnet, model)\n",
    "\n",
    "#     for transform in _TRANSFORMs:\n",
    "#         df_transformed = transform_df(df_codesearchnet, _TRANSFORMs[transform])\n",
    "#         long_range_results[\"codesearchnet_\" + transform] = _get_metrics(\n",
    "#             df_transformed, model\n",
    "#         )\n",
    "\n",
    "    return long_range_results\n",
    "\n",
    "\n",
    "def _counterfactual(control_results, treatment_results):\n",
    "    pass\n",
    "\n",
    "\n",
    "def evaluate(data_path, model_path):\n",
    "    \"\"\"Function for evaluating models related to the library.\"\"\"\n",
    "    results = defaultdict(dict)\n",
    "    testbed_path = data_path / \"controlled/testbeds\"\n",
    "    #     models = []\n",
    "    # These model folders will need to contain the config of the model as well\n",
    "    # to differentiate them\n",
    "    for m_path in model_path.glob(\"*/\"):\n",
    "        model = None\n",
    "        print(m_path)\n",
    "        if m_path.name == \"Transformer\":\n",
    "            model = TransformerModel.from_path(m_path)\n",
    "        elif \"gru\" in m_path.name:\n",
    "            model = RNNModel.from_path(m_path)\n",
    "        elif m_path.name == \"RNN\":\n",
    "            pass\n",
    "#         return model\n",
    "    \n",
    "        bigclone_path = testbed_path / \"_ts_bigclone_types\"\n",
    "        bugfix_path = testbed_path / \"_ts_bug_fix\"\n",
    "        codesearchnet_path = testbed_path / \"codesearchnet\"\n",
    "\n",
    "        # Long-Range Interactions\n",
    "        results[m_path.name][\"long_range\"] = _long_range(\n",
    "            bigclone_path, bugfix_path, codesearchnet_path, model, n=10\n",
    "        )\n",
    "    return dict(results)\n",
    "\n",
    "\n",
    "path = Path(\"/home/jovyan/work\")\n",
    "data_path = path / \"dvc-icodegen/datasets\"\n",
    "model_path = path / \"dvc-icodegen/models\"\n",
    "results = evaluate(data_path, model_path)\n",
    "        # Long-Range Interactions\n",
    "#         results[m_path.name][\"long_range\"] = _long_range(\n",
    "#             bigclone_path, bugfix_path, codesearchnet_path, model\n",
    "#         )\n",
    "\n",
    "#     return results\n",
    "    # Counterfactuals\n",
    "\n",
    "\n",
    "#         results[m_path][\"counterfactual\"] = _counterfactual(data_dir, model)\n",
    "# _counterfactual(control_results, treatment_results)\n",
    "\n",
    "# Save results in json format\n",
    "# Long-Range Interactions\n",
    "#     long_range_results = _long_range(data_dir, models)\n",
    "#     long_range_results\n",
    "\n",
    "#     # Counterfactuals\n",
    "#     counterfactual_results = []\n",
    "#     counterfactual_results\n",
    "#     for transform in _TRANSFORMs:\n",
    "#         pass\n",
    "# _counterfactual(control_results, treatment_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gru_layers1_vocab10000_embed256_units512': {'long_range': {'buggy': {'error_taxonomy': {'blocks': {'<{>': {'error_rate': 1.0,\n",
       "       'count': 28},\n",
       "      '<}>': {'error_rate': 1.0, 'count': 28},\n",
       "      '<[>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<]>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<(>': {'error_rate': 1.0, 'count': 82},\n",
       "      '<)>': {'error_rate': 0.8658536585365854, 'count': 82},\n",
       "      '<;>': {'error_rate': 1.0, 'count': 53},\n",
       "      '<return>': {'error_rate': 1.0, 'count': 12},\n",
       "      'stats': {'mean_error_rate': 0.9832317073170731,\n",
       "       'stdev_error_rate': 0.04436473235016844,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'exceptions': {'<catch>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<try>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<finally>': {'error_rate': nan, 'count': 0},\n",
       "      '<throw>': {'error_rate': nan, 'count': 0},\n",
       "      '<throws>': {'error_rate': 1.0, 'count': 1},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'oop': {'<class>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<instanceof>': {'error_rate': nan, 'count': 0},\n",
       "      '<interface>': {'error_rate': nan, 'count': 0},\n",
       "      '<private>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<protected>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<public>': {'error_rate': 1.0, 'count': 5},\n",
       "      '<abstract>': {'error_rate': nan, 'count': 0},\n",
       "      '<extends>': {'error_rate': nan, 'count': 0},\n",
       "      '<package>': {'error_rate': nan, 'count': 0},\n",
       "      '<this>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<implements>': {'error_rate': nan, 'count': 0},\n",
       "      '<import>': {'error_rate': nan, 'count': 0},\n",
       "      '<new>': {'error_rate': 1.0, 'count': 6},\n",
       "      '<super>': {'error_rate': 1.0, 'count': 2},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'tests': {'<assert>': {'error_rate': 1.0, 'count': 2},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'declarations': {'<native>': {'error_rate': nan, 'count': 0},\n",
       "      '<static>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<synchronized>': {'error_rate': nan, 'count': 0},\n",
       "      '<transient>': {'error_rate': nan, 'count': 0},\n",
       "      '<volatile>': {'error_rate': nan, 'count': 0},\n",
       "      '<void>': {'error_rate': 1.0, 'count': 7},\n",
       "      '<final>': {'error_rate': nan, 'count': 0},\n",
       "      '<enum>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'conditionals': {'<else>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<if>': {'error_rate': 1.0, 'count': 12},\n",
       "      '<switch>': {'error_rate': nan, 'count': 0},\n",
       "      '<case>': {'error_rate': nan, 'count': 0},\n",
       "      '<default>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'loops': {'<break>': {'error_rate': nan, 'count': 0},\n",
       "      '<do>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<for>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<while>': {'error_rate': nan, 'count': 0},\n",
       "      '<continue>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'operators': {'<=>': {'error_rate': 1.0, 'count': 17},\n",
       "      '<+>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<->': {'error_rate': 1.0, 'count': 1},\n",
       "      '<*>': {'error_rate': 1.0, 'count': 2},\n",
       "      '</>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<%>': {'error_rate': nan, 'count': 0},\n",
       "      '<++>': {'error_rate': nan, 'count': 0},\n",
       "      '<-->': {'error_rate': nan, 'count': 0},\n",
       "      '<!>': {'error_rate': 1.0, 'count': 5},\n",
       "      '<==>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<!=>': {'error_rate': 1.0, 'count': 2},\n",
       "      '<greater_equal>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<lesser_equal>': {'error_rate': nan, 'count': 0},\n",
       "      '<&&>': {'error_rate': nan, 'count': 0},\n",
       "      '<||>': {'error_rate': nan, 'count': 0},\n",
       "      '<?>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<:>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<~>': {'error_rate': nan, 'count': 0},\n",
       "      '<double_lesser>': {'error_rate': nan, 'count': 0},\n",
       "      '<double_greater>': {'error_rate': nan, 'count': 0},\n",
       "      '<triple_greater>': {'error_rate': nan, 'count': 0},\n",
       "      '<&>': {'error_rate': nan, 'count': 0},\n",
       "      '<^>': {'error_rate': nan, 'count': 0},\n",
       "      '<|>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'datatypes': {'<byte>': {'error_rate': nan, 'count': 0},\n",
       "      '<char>': {'error_rate': nan, 'count': 0},\n",
       "      '<float>': {'error_rate': nan, 'count': 0},\n",
       "      '<boolean>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<double>': {'error_rate': nan, 'count': 0},\n",
       "      '<int>': {'error_rate': 1.0, 'count': 14},\n",
       "      '<long>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<short>': {'error_rate': nan, 'count': 0},\n",
       "      '<strictfp>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'extra_tokens': {'<@>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<...>': {'error_rate': nan, 'count': 0},\n",
       "      '<null>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<true>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<false>': {'error_rate': nan, 'count': 0},\n",
       "      '<n>': {'error_rate': 1.0, 'count': 100},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}}},\n",
       "    'dist_mean':     dist     mean_prob  std_prob      med_prob  mad_prob\n",
       "    0      8  1.207141e-07  0.000000  1.207141e-07  0.000000\n",
       "    1     12  3.133740e-05  0.000000  3.133740e-05  0.000000\n",
       "    2     14  3.254278e-04  0.000000  3.254278e-04  0.000000\n",
       "    3     16  4.908312e-06  0.000002  4.908312e-06  0.000002\n",
       "    4     18  4.721369e-07  0.000000  4.721369e-07  0.000000\n",
       "    5     21  2.520642e-06  0.000000  2.520642e-06  0.000000\n",
       "    6     41  6.837193e-05  0.000000  6.837193e-05  0.000000\n",
       "    7     45  9.986493e-07  0.000000  9.986493e-07  0.000000\n",
       "    8     47  5.149367e-06  0.000000  5.149367e-06  0.000000\n",
       "    9     55  1.139350e-06  0.000000  1.139350e-06  0.000000\n",
       "    10    57  8.800810e-06  0.000000  8.800810e-06  0.000000\n",
       "    11    73  1.652192e-04  0.000000  1.652192e-04  0.000000\n",
       "    12    76  1.724610e-06  0.000000  1.724610e-06  0.000000\n",
       "    13    87  6.410999e-02  0.000000  6.410999e-02  0.000000\n",
       "    14    95  1.246914e-05  0.000000  1.246914e-05  0.000000\n",
       "    15    98  5.602366e-02  0.000000  5.602366e-02  0.000000\n",
       "    16    99  2.577458e-04  0.000000  2.577458e-04  0.000000\n",
       "    17   101  2.184061e-04  0.000000  2.184061e-04  0.000000\n",
       "    18   130  4.229159e-02  0.000000  4.229159e-02  0.000000\n",
       "    19   148  3.150251e-02  0.000000  3.150251e-02  0.000000\n",
       "    20   159  3.104646e-02  0.000000  3.104646e-02  0.000000\n",
       "    21   171  5.248478e-03  0.000000  5.248478e-03  0.000000\n",
       "    22   173  1.191561e-01  0.000000  1.191561e-01  0.000000\n",
       "    23   216  7.951981e-04  0.000000  7.951981e-04  0.000000,\n",
       "    'mean_cross_entropy': {'mean': 9.728883,\n",
       "     'median': 9.318403,\n",
       "     'std': 2.71132,\n",
       "     'mad': 0.3798942565917969}},\n",
       "   'fixed': {'error_taxonomy': {'blocks': {'<{>': {'error_rate': 1.0,\n",
       "       'count': 28},\n",
       "      '<}>': {'error_rate': 1.0, 'count': 28},\n",
       "      '<[>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<]>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<(>': {'error_rate': 1.0, 'count': 82},\n",
       "      '<)>': {'error_rate': 0.8658536585365854, 'count': 82},\n",
       "      '<;>': {'error_rate': 1.0, 'count': 53},\n",
       "      '<return>': {'error_rate': 1.0, 'count': 12},\n",
       "      'stats': {'mean_error_rate': 0.9832317073170731,\n",
       "       'stdev_error_rate': 0.04436473235016844,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'exceptions': {'<catch>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<try>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<finally>': {'error_rate': nan, 'count': 0},\n",
       "      '<throw>': {'error_rate': nan, 'count': 0},\n",
       "      '<throws>': {'error_rate': 1.0, 'count': 1},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'oop': {'<class>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<instanceof>': {'error_rate': nan, 'count': 0},\n",
       "      '<interface>': {'error_rate': nan, 'count': 0},\n",
       "      '<private>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<protected>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<public>': {'error_rate': 1.0, 'count': 5},\n",
       "      '<abstract>': {'error_rate': nan, 'count': 0},\n",
       "      '<extends>': {'error_rate': nan, 'count': 0},\n",
       "      '<package>': {'error_rate': nan, 'count': 0},\n",
       "      '<this>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<implements>': {'error_rate': nan, 'count': 0},\n",
       "      '<import>': {'error_rate': nan, 'count': 0},\n",
       "      '<new>': {'error_rate': 1.0, 'count': 6},\n",
       "      '<super>': {'error_rate': 1.0, 'count': 2},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'tests': {'<assert>': {'error_rate': 1.0, 'count': 2},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'declarations': {'<native>': {'error_rate': nan, 'count': 0},\n",
       "      '<static>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<synchronized>': {'error_rate': nan, 'count': 0},\n",
       "      '<transient>': {'error_rate': nan, 'count': 0},\n",
       "      '<volatile>': {'error_rate': nan, 'count': 0},\n",
       "      '<void>': {'error_rate': 1.0, 'count': 7},\n",
       "      '<final>': {'error_rate': nan, 'count': 0},\n",
       "      '<enum>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'conditionals': {'<else>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<if>': {'error_rate': 1.0, 'count': 12},\n",
       "      '<switch>': {'error_rate': nan, 'count': 0},\n",
       "      '<case>': {'error_rate': nan, 'count': 0},\n",
       "      '<default>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'loops': {'<break>': {'error_rate': nan, 'count': 0},\n",
       "      '<do>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<for>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<while>': {'error_rate': nan, 'count': 0},\n",
       "      '<continue>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'operators': {'<=>': {'error_rate': 1.0, 'count': 17},\n",
       "      '<+>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<->': {'error_rate': 1.0, 'count': 1},\n",
       "      '<*>': {'error_rate': 1.0, 'count': 2},\n",
       "      '</>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<%>': {'error_rate': nan, 'count': 0},\n",
       "      '<++>': {'error_rate': nan, 'count': 0},\n",
       "      '<-->': {'error_rate': nan, 'count': 0},\n",
       "      '<!>': {'error_rate': 1.0, 'count': 5},\n",
       "      '<==>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<!=>': {'error_rate': 1.0, 'count': 2},\n",
       "      '<greater_equal>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<lesser_equal>': {'error_rate': nan, 'count': 0},\n",
       "      '<&&>': {'error_rate': nan, 'count': 0},\n",
       "      '<||>': {'error_rate': nan, 'count': 0},\n",
       "      '<?>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<:>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<~>': {'error_rate': nan, 'count': 0},\n",
       "      '<double_lesser>': {'error_rate': nan, 'count': 0},\n",
       "      '<double_greater>': {'error_rate': nan, 'count': 0},\n",
       "      '<triple_greater>': {'error_rate': nan, 'count': 0},\n",
       "      '<&>': {'error_rate': nan, 'count': 0},\n",
       "      '<^>': {'error_rate': nan, 'count': 0},\n",
       "      '<|>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'datatypes': {'<byte>': {'error_rate': nan, 'count': 0},\n",
       "      '<char>': {'error_rate': nan, 'count': 0},\n",
       "      '<float>': {'error_rate': nan, 'count': 0},\n",
       "      '<boolean>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<double>': {'error_rate': nan, 'count': 0},\n",
       "      '<int>': {'error_rate': 1.0, 'count': 14},\n",
       "      '<long>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<short>': {'error_rate': nan, 'count': 0},\n",
       "      '<strictfp>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'extra_tokens': {'<@>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<...>': {'error_rate': nan, 'count': 0},\n",
       "      '<null>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<true>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<false>': {'error_rate': nan, 'count': 0},\n",
       "      '<n>': {'error_rate': 1.0, 'count': 100},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}}},\n",
       "    'dist_mean':     dist     mean_prob  std_prob      med_prob  mad_prob\n",
       "    0      8  2.514261e-06  0.000002  2.514261e-06  0.000002\n",
       "    1     12  3.133740e-05  0.000000  3.133740e-05  0.000000\n",
       "    2     14  3.254278e-04  0.000000  3.254278e-04  0.000000\n",
       "    3     16  2.813610e-06  0.000000  2.813610e-06  0.000000\n",
       "    4     18  4.721369e-07  0.000000  4.721369e-07  0.000000\n",
       "    5     21  3.923531e-06  0.000001  3.923531e-06  0.000001\n",
       "    6     41  6.837193e-05  0.000000  6.837193e-05  0.000000\n",
       "    7     47  5.149367e-06  0.000000  5.149367e-06  0.000000\n",
       "    8     50  1.426494e-06  0.000000  1.426494e-06  0.000000\n",
       "    9     55  1.139350e-06  0.000000  1.139350e-06  0.000000\n",
       "    10    57  8.800810e-06  0.000000  8.800810e-06  0.000000\n",
       "    11    76  1.724610e-06  0.000000  1.724610e-06  0.000000\n",
       "    12    87  6.347100e-02  0.000000  6.347100e-02  0.000000\n",
       "    13    94  1.502765e-02  0.014779  1.502765e-02  0.014779\n",
       "    14    95  1.327239e-05  0.000000  1.327239e-05  0.000000\n",
       "    15    99  3.265051e-05  0.000000  3.265051e-05  0.000000\n",
       "    16   104  4.238477e-04  0.000000  4.238477e-04  0.000000\n",
       "    17   135  4.673224e-02  0.000000  4.673224e-02  0.000000\n",
       "    18   148  2.086460e-01  0.000000  2.086460e-01  0.000000\n",
       "    19   156  2.981598e-02  0.000000  2.981598e-02  0.000000\n",
       "    20   159  3.092586e-02  0.000000  3.092586e-02  0.000000\n",
       "    21   171  5.079383e-03  0.000000  5.079383e-03  0.000000\n",
       "    22   222  1.679451e-04  0.000000  1.679451e-04  0.000000,\n",
       "    'mean_cross_entropy': {'mean': 9.721969,\n",
       "     'median': 9.318403,\n",
       "     'std': 2.6962547,\n",
       "     'mad': 0.35593461990356445}}}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_range_results = _long_range(Path(\"/tmp\"), model, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_data.core.ipynb.\n",
      "Converted 01_data.transforms.ipynb.\n",
      "Converted 02_model.core.ipynb.\n",
      "Converted 04_evaluation.core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
