{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp evaluation.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from icodegen.data.transforms import (\n",
    "    code_token_randomizer,\n",
    "    line_randomizer,\n",
    "    java_comment_remover,\n",
    "    transform_df,\n",
    ")\n",
    "from icodegen.model.core import Model, RNNModel\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from typing import Dict, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at sshleifer/tiny-gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# Setting up testing data\n",
    "from transformers import GPT2TokenizerFast, TFGPT2LMHeadModel\n",
    "from icodegen.model.core import RNNModel\n",
    "\n",
    "# Using tiny-gpt2 for just quick tests since it is... tiny :)\n",
    "trnsfr_tokenizer = GPT2TokenizerFast.from_pretrained(\"sshleifer/tiny-gpt2\")\n",
    "tokenizer = trnsfr_tokenizer.backend_tokenizer\n",
    "trnsfr = TFGPT2LMHeadModel.from_pretrained(\"sshleifer/tiny-gpt2\")\n",
    "# trnsfr_model = TransformerModel(tokenizer, trnsfr)\n",
    "\n",
    "rnn_type = \"gru\"\n",
    "n_layers = 1\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "embedding_dim = 128\n",
    "rnn_units = 128\n",
    "batch_size = 1\n",
    "out_path = \"/tmp\"\n",
    "gru_model = RNNModel(\n",
    "    rnn_type,\n",
    "    n_layers,\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    rnn_units,\n",
    "    batch_size,\n",
    "    out_path,\n",
    "    tokenizer,\n",
    ")\n",
    "\n",
    "df_fake = pd.DataFrame(\n",
    "    [\"aaaa(bb(aaaa(bb()()ccc)dd)()ccc)dd\", \"aaaa(bb()ccccc)dd\"], columns=[\"code\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_mean_probs(df: pd.DataFrame, model: Model, n: Optional[int] = None):\n",
    "    \"\"\"\n",
    "    Get the mean probability of each token that the model\n",
    "    should predict for an entire pandas dataframe.\n",
    "\n",
    "    :param df: the pandas dataframe containing each method to have the model predict on\n",
    "    :param model: the model used to generate the predictions\n",
    "    :param n: the number of methods to evaluate. If none, the entire dataframe will be used\n",
    "    :returns: returns a numpy array of the mean probability for each token in the model's vocab\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        n = len(df)\n",
    "\n",
    "    # setup container lists for the number of occurrences and sum of probabilities for each token\n",
    "    counts = [0] * model.tokenizer.get_vocab_size()\n",
    "    sum_probs = [0.0] * model.tokenizer.get_vocab_size()\n",
    "    # loop through each method\n",
    "    for mthd in df.code.values[:n]:\n",
    "        # token the method and generate the probabilities for the model's predictions\n",
    "        inputs = model.tokenize(mthd)\n",
    "        probs = model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "        # loop through each token and its probability and update the container lists\n",
    "        for idx, p in zip(inputs[\"input_ids\"][0], probs):\n",
    "            counts[idx] += 1\n",
    "            sum_probs[idx] += p[idx]\n",
    "\n",
    "    # convert the lists to numpy lists and perform element wise division to get the mean probabilities for each token\n",
    "    counts = np.array(counts)\n",
    "    sum_probs = np.array(sum_probs)\n",
    "\n",
    "    # perform division, but not when denominator is zero. In those cases, just leave value as NAN.\n",
    "    nans = np.empty(counts.shape)\n",
    "    nans.fill(np.nan)\n",
    "    mean_probs = np.divide(sum_probs, counts, out=nans, where=counts != 0)\n",
    "    # TODO: convert to dictionary with keys as tokens\n",
    "    mean_probs = {\n",
    "        model.tokenizer.id_to_token(i): mean_probs[i] for i in range(len(mean_probs))\n",
    "    }\n",
    "    return mean_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_NAN_PROBS_MEAN = np.array(\n",
    "    [\n",
    "        2.01237513e-05,\n",
    "        1.98944481e-05,\n",
    "        2.01449202e-05,\n",
    "        2.04353437e-05,\n",
    "        2.02043060e-05,\n",
    "        2.02826177e-05,\n",
    "        2.09888076e-05,\n",
    "        2.07051467e-05,\n",
    "        1.98100976e-05,\n",
    "        2.02152678e-05,\n",
    "        2.02035244e-05,\n",
    "        2.10283021e-05,\n",
    "    ]\n",
    ")\n",
    "\n",
    "mean_probs = np.array(list(get_mean_probs(df_fake, trnsfr_model).values()))\n",
    "non_nan_idx = np.argwhere(~np.isnan(mean_probs)).flatten()\n",
    "non_nan_mean_prob = mean_probs[non_nan_idx]\n",
    "\n",
    "assert np.isclose(non_nan_mean_prob, NON_NAN_PROBS_MEAN, atol=1.0e-6).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_NAN_PROBS_MEAN = np.array(\n",
    "    [\n",
    "        1.99270412e-05,\n",
    "        1.99168703e-05,\n",
    "        1.98815596e-05,\n",
    "        1.99057849e-05,\n",
    "        1.98800869e-05,\n",
    "        1.98893995e-05,\n",
    "        1.98797388e-05,\n",
    "        1.98960342e-05,\n",
    "        1.99086674e-05,\n",
    "        1.98605580e-05,\n",
    "        1.98807957e-05,\n",
    "        1.98842057e-05,\n",
    "    ]\n",
    ")\n",
    "\n",
    "mean_probs = np.array(list(get_mean_probs(df_fake, gru_model).values()))\n",
    "non_nan_idx = np.argwhere(~np.isnan(mean_probs)).flatten()\n",
    "non_nan_mean_prob = mean_probs[non_nan_idx]\n",
    "\n",
    "assert np.isclose(non_nan_mean_prob, NON_NAN_PROBS_MEAN, atol=1.0e-6).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def find_parens(toks: List[str], opening: str, closing: str) -> Dict[int, int]:\n",
    "    \"\"\"\n",
    "    Get the indices for the opening and closing tokens.\n",
    "    From https://stackoverflow.com/a/29992065/5768407\n",
    "    by user Baltasarq (https://stackoverflow.com/users/266978/baltasarq).\n",
    "\n",
    "    :param toks: the tokenized version of a method\n",
    "    :param opening: the opening token that will be matched against the closing token\n",
    "    :param closing: the closing token that will be matched against the opening token\n",
    "    :returns: returns a dictionary with the opening token indices as the keys and the closing token indices as the values\n",
    "    \"\"\"\n",
    "    toret = {}\n",
    "    pstack = []\n",
    "\n",
    "    for i, tok in enumerate(toks):\n",
    "        if tok == opening:\n",
    "            pstack.append(i)\n",
    "        elif tok == closing:\n",
    "            if len(pstack) == 0:\n",
    "                raise IndexError(\"No matching closing parens at: \" + str(i))\n",
    "            toret[pstack.pop()] = i\n",
    "\n",
    "    if len(pstack) > 0:\n",
    "        raise IndexError(\"No matching opening parens at: \" + str(pstack.pop()))\n",
    "\n",
    "    return toret\n",
    "\n",
    "\n",
    "def _get_dist_probs(\n",
    "    mthd: str, model: Model, opening: str, closing: str\n",
    ") -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Get the distances and mean probabilities between opening and closing tokens in a given method.\n",
    "\n",
    "    :param mthd: the method to get the ranges of the opening and closing tokens and their probabilities\n",
    "    :param model: the model used to generate the predictions\n",
    "    :param opening: the opening token used for calculating the distance between opening and closing tokens\n",
    "    :param closing: the closing token used for calculating the distance between opening and closing tokens as well as the token to get the mean probability of\n",
    "    :returns: returns a dictionary with the distance between the opening and closing tokens as keys and their mean probabilities as values\n",
    "    \"\"\"\n",
    "    # WARNING: Careful when using different tokenizers since HF tokenizers lib have diff API then HF transformers lib tokenizers... You will need to update this when using custom model and tokenizer...\n",
    "\n",
    "    # get the distances for the opening and closing tokens\n",
    "    toks = model.tokenizer.encode(mthd).tokens\n",
    "    idxs = find_parens(toks, opening, closing)\n",
    "\n",
    "    # get the model probabilities for the given method\n",
    "    inputs = model.tokenize(mthd)\n",
    "    probs = model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "    # sum up the probabilities of the different distances for the closing token\n",
    "    dist_probs = defaultdict(float)\n",
    "    for open_id, close_id in idxs.items():\n",
    "        dist_probs[close_id - open_id] += probs[close_id][\n",
    "            inputs[\"input_ids\"][0][close_id]\n",
    "        ]\n",
    "\n",
    "    # get the mean of the summed probabilities\n",
    "    dist_cnts = Counter([close_id - open_id for open_id, close_id in idxs.items()])\n",
    "    dist_probs = {dist: dist_probs[dist] / n for dist, n in dist_cnts.items()}\n",
    "    return dist_probs\n",
    "\n",
    "\n",
    "def mean_dist_probs(\n",
    "    df: pd.DataFrame,\n",
    "    model: Model,\n",
    "    opening: Optional[str] = \"<{>\",\n",
    "    closing: Optional[str] = \"<}>\",\n",
    "    n: Optional[int] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get the distance between opening and closing tokens and the mean probability of each closing token that the model should predict for an entire pandas dataframe.\n",
    "\n",
    "    :param df: the pandas dataframe containing each method to have the model predict on\n",
    "    :param model: the model used to generate the predictions\n",
    "    :param opening: the opening token used for calculating the distance between opening and closing tokens\n",
    "    :param closing: the closing token used for calculating the distance between opening and closing tokens as well as the token to get the mean probability of\n",
    "    :param n: the number of methods to evaluate. If none, the entire dataframe will be used\n",
    "    :returns: returns a dataframe with the distances between opening and closing tokens and their mean probabilities\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        n = len(df)\n",
    "\n",
    "    # get the probabilities for the different distances for an entire dataframe\n",
    "    df = df.iloc[:n].copy()\n",
    "    dist_probs = df.code.apply(\n",
    "        lambda mthd: _get_dist_probs(mthd, model, opening, closing)\n",
    "    ).values\n",
    "\n",
    "    # flatten the keys of the different distances into a list\n",
    "    dist_keys = []\n",
    "    for probs in dist_probs:\n",
    "        dist_keys.extend(probs.keys())\n",
    "    # merge dictionaries across methods by taking the mean of probs with the same distance. Modified from https://stackoverflow.com/a/10461916/5768407,\n",
    "    # users georg https://stackoverflow.com/users/989121/georg and RÃ©my Hosseinkhan Boucher https://stackoverflow.com/users/12149730/r%c3%a9my-hosseinkhan-boucher\n",
    "    mean_dist_probs = {\n",
    "        k: np.nanmean(np.array([probs.get(k, np.nan) for probs in dist_probs]))\n",
    "        for k in set(dist_keys)\n",
    "    }\n",
    "    std_dist_probs = {\n",
    "        k: np.nanstd(np.array([probs.get(k, np.nan) for probs in dist_probs]))\n",
    "        for k in set(dist_keys)\n",
    "    }\n",
    "\n",
    "    med_dist_probs = {\n",
    "        k: np.nanmedian(np.array([probs.get(k, np.nan) for probs in dist_probs]))\n",
    "        for k in set(dist_keys)\n",
    "    }\n",
    "    mad_dist_probs = {\n",
    "        k: stats.median_abs_deviation(\n",
    "            np.array([probs.get(k, np.nan) for probs in dist_probs]), nan_policy=\"omit\"\n",
    "        )\n",
    "        for k in set(dist_keys)\n",
    "    }\n",
    "    # TODO: convert to dictionary\n",
    "    df_dist = (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"dist\": list(mean_dist_probs.keys()),\n",
    "                \"mean_prob\": list(mean_dist_probs.values()),\n",
    "                \"std_prob\": list(std_dist_probs.values()),\n",
    "                \"med_prob\": list(med_dist_probs.values()),\n",
    "                \"mad_prob\": list(mad_dist_probs.values()),\n",
    "            }\n",
    "        )\n",
    "        .sort_values(\"dist\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return df_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIST_DF = pd.DataFrame(\n",
    "    {\n",
    "        \"dist\": [6, 10, 16],\n",
    "        \"mean_prob\": [\n",
    "            1.98822217e-05,\n",
    "            1.97613608e-05,\n",
    "            1.97816771e-05,\n",
    "        ],\n",
    "        \"std_prob\": [\n",
    "            4.93400876e-09,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "        ],\n",
    "        \"med_prob\": [\n",
    "            2.04683793e-05,\n",
    "            2.07205376e-05,\n",
    "            1.97817026e-05,\n",
    "        ],\n",
    "        \"mad_prob\": [\n",
    "            4.93400876e-09,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "df_dist = mean_dist_probs(df_fake, gru_model, opening=\"(\", closing=\")\")\n",
    "\n",
    "assert (DIST_DF.dist.values == df_dist.dist.values).all()\n",
    "assert np.isclose(DIST_DF.mean_prob.values, df_dist.mean_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.std_prob.values, df_dist.std_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.med_prob.values, df_dist.med_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.mad_prob.values, df_dist.mad_prob.values, atol=1.0e-6).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIST_DF = pd.DataFrame(\n",
    "    {\n",
    "        \"dist\": [6, 10, 16],\n",
    "        \"mean_prob\": [\n",
    "            1.98822217e-05,\n",
    "            1.97613608e-05,\n",
    "            1.97816771e-05,\n",
    "        ],\n",
    "        \"std_prob\": [\n",
    "            4.93400876e-09,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "        ],\n",
    "        \"med_prob\": [\n",
    "            2.04683793e-05,\n",
    "            2.07205376e-05,\n",
    "            1.97817026e-05,\n",
    "        ],\n",
    "        \"mad_prob\": [\n",
    "            4.93400876e-09,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "df_dist = mean_dist_probs(df_fake, trnsfr_model, opening=\"(\", closing=\")\")\n",
    "\n",
    "assert (DIST_DF.dist.values == df_dist.dist.values).all()\n",
    "assert np.isclose(DIST_DF.mean_prob.values, df_dist.mean_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.std_prob.values, df_dist.std_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.med_prob.values, df_dist.med_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.mad_prob.values, df_dist.mad_prob.values, atol=1.0e-6).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "token_taxonomy = {\n",
    "  \"blocks\": {\n",
    "    \"<{>\": \"{\",\n",
    "    \"<}>\": \"}\",\n",
    "    \"<[>\": \"[\",\n",
    "    \"<]>\": \"]\",\n",
    "    \"<(>\": \"(\",\n",
    "    \"<)>\": \")\",\n",
    "    \"<;>\": \";\",\n",
    "    \"<return>\": \"return\"\n",
    "  },\n",
    "  \"exceptions\": {\n",
    "    \"<catch>\": \"catch\",\n",
    "    \"<try>\": \"try\",\n",
    "    \"<finally>\": \"finally\",\n",
    "    \"<throw>\": \"throw\",\n",
    "    \"<throws>\": \"throws\"\n",
    "  },\n",
    "  \"oop\": {\n",
    "    \"<class>\": \"class\",\n",
    "    \"<instanceof>\": \"instanceof\",\n",
    "    \"<interface>\": \"interface\",\n",
    "    \"<private>\": \"private\",\n",
    "    \"<protected>\": \"protected\",\n",
    "    \"<public>\": \"public\",\n",
    "    \"<abstract>\": \"abstract\",\n",
    "    \"<extends>\": \"extends\",\n",
    "    \"<package>\": \"package\",\n",
    "    \"<this>\": \"this\",\n",
    "    \"<implements>\": \"implements\",\n",
    "    \"<import>\": \"import\",\n",
    "    \"<new>\": \"new\",\n",
    "    \"<super>\": \"super\"\n",
    "  },\n",
    "  \"tests\": {\n",
    "    \"<assert>\": \"assert\"\n",
    "  },\n",
    "  \"declarations\": {\n",
    "    \"<native>\": \"native\",\n",
    "    \"<static>\": \"static\",\n",
    "    \"<synchronized>\": \"synchronized\",\n",
    "    \"<transient>\": \"transient\",\n",
    "    \"<volatile>\": \"volatile\",\n",
    "    \"<void>\": \"void\",\n",
    "    \"<final>\": \"final\",\n",
    "    \"<enum>\": \"enum\"\n",
    "  },\n",
    "  \"conditionals\": {\n",
    "    \"<else>\": \"else\",\n",
    "    \"<if>\": \"if\",\n",
    "    \"<switch>\": \"switch\",\n",
    "    \"<case>\": \"case\",\n",
    "    \"<default>\": \"default\"\n",
    "  },\n",
    "  \"loops\": {\n",
    "    \"<break>\": \"break\",\n",
    "    \"<do>\": \"do\",\n",
    "    \"<for>\": \"for\",\n",
    "    \"<while>\": \"while\",\n",
    "    \"<continue>\": \"continue\"\n",
    "  },\n",
    "  \"operators\": {\n",
    "    \"<=>\": \"=\",\n",
    "    \"<+>\": \"+\",\n",
    "    \"<->\": \"-\",\n",
    "    \"<*>\": \"*\",\n",
    "    \"</>\": \"/\",\n",
    "    \"<%>\": \"%\",\n",
    "    \"<++>\": \"++\",\n",
    "    \"<-->\": \"--\",\n",
    "    \"<!>\": \"!\",\n",
    "    \"<==>\": \"==\",\n",
    "    \"<!=>\": \"!=\",\n",
    "    \"<greater_equal>\": \">=\",\n",
    "    \"<lesser_equal>\": \"<=\",\n",
    "    \"<&&>\": \"&&\",\n",
    "    \"<||>\": \"||\",\n",
    "    \"<?>\": \"?\",\n",
    "    \"<:>\": \":\",\n",
    "    \"<~>\": \"~\",\n",
    "    \"<double_lesser>\": \"<<\",\n",
    "    \"<double_greater>\": \">>\",\n",
    "    \"<triple_greater>\": \">>>\",\n",
    "    \"<&>\": \"&\",\n",
    "    \"<^>\": \"^\",\n",
    "    \"<|>\": \"|\"\n",
    "  },\n",
    "  \"datatypes\": {\n",
    "    \"<byte>\": \"byte\",\n",
    "    \"<char>\": \"char\",\n",
    "    \"<float>\": \"float\",\n",
    "    \"<boolean>\": \"boolean\",\n",
    "    \"<double>\": \"double\",\n",
    "    \"<int>\": \"int\",\n",
    "    \"<long>\": \"long\",\n",
    "    \"<short>\": \"short\",\n",
    "    \"<strictfp>\": \"strictfp\"\n",
    "  },\n",
    "  \"extra_tokens\": {\n",
    "    \"<@>\": \"@\",\n",
    "    \"<...>\": \"...\",\n",
    "    \"<null>\": \"null\",\n",
    "    \"<true>\": \"true\",\n",
    "    \"<false>\": \"false\",\n",
    "    \"<n>\": \"\\n\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "ERROR_THRESHOLD = 0.5\n",
    "\n",
    "def get_error_rates(df: pd.DataFrame, model: Model, n: Optional[int] = None):\n",
    "    if n is None:\n",
    "        n = len(df)\n",
    "\n",
    "    # setup container lists for the number of occurrences and sum of probabilities for each token\n",
    "    cnts = [0] * model.tokenizer.get_vocab_size()\n",
    "    err_cnts = [0] * model.tokenizer.get_vocab_size()\n",
    "    # loop through each method\n",
    "    for mthd in df.code.values[:n]:\n",
    "        # token the method and generate the probabilities for the model's predictions\n",
    "        inputs = model.tokenize(mthd)\n",
    "        probs = model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "        # loop through each token and its probability and update the container lists\n",
    "        for idx, p in zip(inputs[\"input_ids\"][0], probs):\n",
    "            cnts[idx] += 1\n",
    "            if p[idx] < ERROR_THRESHOLD:\n",
    "                err_cnts[idx] += 1\n",
    "\n",
    "    # convert the lists to numpy lists and perform element wise division to get the mean probabilities for each token\n",
    "    cnts = np.array(cnts)\n",
    "    err_cnts = np.array(err_cnts)\n",
    "\n",
    "    # perform division, but not when denominator is zero. In those cases, just leave value as NAN.\n",
    "    nans = np.empty(cnts.shape)\n",
    "    nans.fill(np.nan)\n",
    "    mean_errs = np.divide(err_cnts, cnts, out=nans, where=cnts != 0)\n",
    "    \n",
    "    error_taxonomy = token_taxonomy.copy()\n",
    "    \n",
    "    for cat, tokens in error_taxonomy.items():\n",
    "        errs = []\n",
    "        cnt_sum = 0\n",
    "        for token, keyword in tokens.items():\n",
    "            idx = model.tokenizer.token_to_id(token)\n",
    "            error_taxonomy[cat][token] = {\"error_rate\": mean_errs[idx], \"count\": cnts[idx]}\n",
    "            errs.append(mean_errs[idx])\n",
    "            cnt_sum += cnts[idx]\n",
    "\n",
    "        errs = np.array(errs)\n",
    "        error_taxonomy[cat][\"stats\"] = {\n",
    "            \"mean_error_rate\": np.nanmean(errs),\n",
    "            \"stdev_error_rate\": np.nanstd(errs),\n",
    "            \"median_error_rate\": np.nanmedian(errs),\n",
    "            \"mad_error_rate\": stats.median_abs_deviation(errs, nan_policy=\"omit\"),\n",
    "        }\n",
    "    \n",
    "    return error_taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blocks': {'<{>': {'error_rate': 1.0, 'count': 27},\n",
       "  '<}>': {'error_rate': 1.0, 'count': 27},\n",
       "  '<[>': {'error_rate': 1.0, 'count': 3},\n",
       "  '<]>': {'error_rate': 1.0, 'count': 3},\n",
       "  '<(>': {'error_rate': 1.0, 'count': 81},\n",
       "  '<)>': {'error_rate': 0.8888888888888888, 'count': 81},\n",
       "  '<;>': {'error_rate': 1.0, 'count': 53},\n",
       "  '<return>': {'error_rate': 1.0, 'count': 10},\n",
       "  'stats': {'mean_error_rate': 0.9861111111111112,\n",
       "   'stdev_error_rate': 0.03674654598700822,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'exceptions': {'<catch>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<try>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<finally>': {'error_rate': nan, 'count': 0},\n",
       "  '<throw>': {'error_rate': nan, 'count': 0},\n",
       "  '<throws>': {'error_rate': 1.0, 'count': 1},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'oop': {'<class>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<instanceof>': {'error_rate': nan, 'count': 0},\n",
       "  '<interface>': {'error_rate': nan, 'count': 0},\n",
       "  '<private>': {'error_rate': 1.0, 'count': 3},\n",
       "  '<protected>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<public>': {'error_rate': 1.0, 'count': 5},\n",
       "  '<abstract>': {'error_rate': nan, 'count': 0},\n",
       "  '<extends>': {'error_rate': nan, 'count': 0},\n",
       "  '<package>': {'error_rate': nan, 'count': 0},\n",
       "  '<this>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<implements>': {'error_rate': nan, 'count': 0},\n",
       "  '<import>': {'error_rate': nan, 'count': 0},\n",
       "  '<new>': {'error_rate': 1.0, 'count': 6},\n",
       "  '<super>': {'error_rate': 1.0, 'count': 2},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'tests': {'<assert>': {'error_rate': 1.0, 'count': 2},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'declarations': {'<native>': {'error_rate': nan, 'count': 0},\n",
       "  '<static>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<synchronized>': {'error_rate': nan, 'count': 0},\n",
       "  '<transient>': {'error_rate': nan, 'count': 0},\n",
       "  '<volatile>': {'error_rate': nan, 'count': 0},\n",
       "  '<void>': {'error_rate': 1.0, 'count': 7},\n",
       "  '<final>': {'error_rate': nan, 'count': 0},\n",
       "  '<enum>': {'error_rate': nan, 'count': 0},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'conditionals': {'<else>': {'error_rate': 1.0, 'count': 4},\n",
       "  '<if>': {'error_rate': 1.0, 'count': 11},\n",
       "  '<switch>': {'error_rate': nan, 'count': 0},\n",
       "  '<case>': {'error_rate': nan, 'count': 0},\n",
       "  '<default>': {'error_rate': nan, 'count': 0},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'loops': {'<break>': {'error_rate': nan, 'count': 0},\n",
       "  '<do>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<for>': {'error_rate': 1.0, 'count': 4},\n",
       "  '<while>': {'error_rate': nan, 'count': 0},\n",
       "  '<continue>': {'error_rate': nan, 'count': 0},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'operators': {'<=>': {'error_rate': 1.0, 'count': 18},\n",
       "  '<+>': {'error_rate': 1.0, 'count': 3},\n",
       "  '<->': {'error_rate': 1.0, 'count': 2},\n",
       "  '<*>': {'error_rate': 1.0, 'count': 2},\n",
       "  '</>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<%>': {'error_rate': nan, 'count': 0},\n",
       "  '<++>': {'error_rate': nan, 'count': 0},\n",
       "  '<-->': {'error_rate': nan, 'count': 0},\n",
       "  '<!>': {'error_rate': 1.0, 'count': 5},\n",
       "  '<==>': {'error_rate': 1.0, 'count': 4},\n",
       "  '<!=>': {'error_rate': 1.0, 'count': 2},\n",
       "  '<greater_equal>': {'error_rate': nan, 'count': 0},\n",
       "  '<lesser_equal>': {'error_rate': nan, 'count': 0},\n",
       "  '<&&>': {'error_rate': nan, 'count': 0},\n",
       "  '<||>': {'error_rate': nan, 'count': 0},\n",
       "  '<?>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<:>': {'error_rate': 1.0, 'count': 4},\n",
       "  '<~>': {'error_rate': nan, 'count': 0},\n",
       "  '<double_lesser>': {'error_rate': nan, 'count': 0},\n",
       "  '<double_greater>': {'error_rate': nan, 'count': 0},\n",
       "  '<triple_greater>': {'error_rate': nan, 'count': 0},\n",
       "  '<&>': {'error_rate': nan, 'count': 0},\n",
       "  '<^>': {'error_rate': nan, 'count': 0},\n",
       "  '<|>': {'error_rate': nan, 'count': 0},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'datatypes': {'<byte>': {'error_rate': nan, 'count': 0},\n",
       "  '<char>': {'error_rate': nan, 'count': 0},\n",
       "  '<float>': {'error_rate': nan, 'count': 0},\n",
       "  '<boolean>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<double>': {'error_rate': nan, 'count': 0},\n",
       "  '<int>': {'error_rate': 1.0, 'count': 15},\n",
       "  '<long>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<short>': {'error_rate': nan, 'count': 0},\n",
       "  '<strictfp>': {'error_rate': nan, 'count': 0},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}},\n",
       " 'extra_tokens': {'<@>': {'error_rate': 1.0, 'count': 4},\n",
       "  '<...>': {'error_rate': nan, 'count': 0},\n",
       "  '<null>': {'error_rate': 1.0, 'count': 2},\n",
       "  '<true>': {'error_rate': 1.0, 'count': 4},\n",
       "  '<false>': {'error_rate': 1.0, 'count': 1},\n",
       "  '<n>': {'error_rate': 1.0, 'count': 98},\n",
       "  'stats': {'mean_error_rate': 1.0,\n",
       "   'stdev_error_rate': 0.0,\n",
       "   'median_error_rate': 1.0,\n",
       "   'mad_error_rate': 0.0}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugfix_path = Path(\"/home/jovyan/work/dvc-icodegen/datasets/controlled/testbeds/_ts_bug_fix\")\n",
    "df_buggy = pd.read_json(bugfix_path / \"buggy.jsonl\", orient=\"records\", lines=True)[\n",
    "    :10\n",
    "]\n",
    "model = RNNModel.from_path(\"/home/jovyan/work/dvc-icodegen/models/gru_layers1_vocab10000_embed256_units512\")\n",
    "err_tax = get_error_rates(df_buggy, model)\n",
    "err_tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "ERROR_THRESHOLD = 0.5\n",
    "\n",
    "def get_error_rates_df(df: pd.DataFrame, model: Model, bs: int = 16, n: Optional[int] = None):\n",
    "    if n is None:\n",
    "        n = len(df)\n",
    "\n",
    "    # setup container lists for the number of occurrences and sum of probabilities for each token\n",
    "    rows = []\n",
    "    # loop through each method\n",
    "    for mthd in df.code.values[:n]:\n",
    "        # token the method and generate the probabilities for the model's predictions\n",
    "        inputs = model.tokenize(mthd)\n",
    "        probs = model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "        row = {k: [0] * model.tokenizer.get_vocab_size() for k in token_taxonomy.keys()}\n",
    "        # loop through each token and its probability and update the container lists\n",
    "        for idx, p in zip(inputs[\"input_ids\"][0], probs):\n",
    "            if p[idx] < ERROR_THRESHOLD:\n",
    "                tok = model.tokenizer.id_to_token(idx)\n",
    "                for k in token_taxonomy:\n",
    "                    if tok in token_taxonomy[k]:\n",
    "                        row[k][idx] += 1\n",
    "        \n",
    "        for k in row:\n",
    "            row[k] = np.mean(row[k])\n",
    "        \n",
    "        rows.append(row)\n",
    "        \n",
    "#     for i in range(0, n, bs):\n",
    "#         batch = [\"<sos>\" + mthd for mthd in df.code.values[i:i + bs]]\n",
    "#         # token the method and get the probabilities for each token from the model\n",
    "#         inputs = tf.stack([x.ids for x in model.tokenizer.encode_batch(batch)], axis = 0)\n",
    "#         logits = model.model(inputs)\n",
    "#         probs = tf.nn.softmax(logits).numpy()\n",
    "        \n",
    "#         for i in range(len(batch)):\n",
    "#             row = {k: [0] * model.tokenizer.get_vocab_size() for k in token_taxonomy.keys()}\n",
    "#             # loop through each token and its probability and update the container lists\n",
    "#             for idx, p in zip(inputs[i], probs[i]):\n",
    "#                 if p[idx] < ERROR_THRESHOLD:\n",
    "#                     tok = model.tokenizer.id_to_token(idx)\n",
    "#                     for k in token_taxonomy:\n",
    "#                         if tok in token_taxonomy[k]:\n",
    "#                             row[k][idx] += 1\n",
    "\n",
    "#             for k in row:\n",
    "#                 row[k] = np.mean(row[k])\n",
    "\n",
    "#             rows.append(row)\n",
    "        \n",
    "    error_df = pd.DataFrame(rows)\n",
    "    error_df[\"code\"] = df.code.values[:n]\n",
    "    \n",
    "    return error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bugfix_path = Path(\"/home/jovyan/work/dvc-icodegen/datasets/controlled/testbeds/_ts_bug_fix\")\n",
    "df_buggy = pd.read_json(bugfix_path / \"buggy.jsonl\", orient=\"records\", lines=True)[\n",
    "    :100\n",
    "]\n",
    "model = RNNModel.from_path(\"/home/jovyan/work/dvc-icodegen/models/controlled/rnns/rnn_layers1_vocab10000_embed256_units1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blocks</th>\n",
       "      <th>exceptions</th>\n",
       "      <th>oop</th>\n",
       "      <th>tests</th>\n",
       "      <th>declarations</th>\n",
       "      <th>conditionals</th>\n",
       "      <th>loops</th>\n",
       "      <th>operators</th>\n",
       "      <th>datatypes</th>\n",
       "      <th>extra_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.00106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.00042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.002550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.00100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.00130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.00280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           blocks  exceptions         oop       tests  declarations  \\\n",
       "count  100.000000  100.000000  100.000000  100.000000    100.000000   \n",
       "mean     0.002949    0.000052    0.000232    0.000013      0.000087   \n",
       "std      0.000782    0.000102    0.000196    0.000058      0.000101   \n",
       "min      0.001300    0.000000    0.000000    0.000000      0.000000   \n",
       "25%      0.002550    0.000000    0.000100    0.000000      0.000000   \n",
       "50%      0.002900    0.000000    0.000200    0.000000      0.000100   \n",
       "75%      0.003500    0.000100    0.000300    0.000000      0.000100   \n",
       "max      0.004900    0.000500    0.001500    0.000300      0.000700   \n",
       "\n",
       "       conditionals       loops   operators   datatypes  extra_tokens  \n",
       "count    100.000000  100.000000  100.000000  100.000000     100.00000  \n",
       "mean       0.000141    0.000070    0.000415    0.000124       0.00106  \n",
       "std        0.000213    0.000124    0.000299    0.000187       0.00042  \n",
       "min        0.000000    0.000000    0.000000    0.000000       0.00030  \n",
       "25%        0.000000    0.000000    0.000200    0.000000       0.00080  \n",
       "50%        0.000100    0.000000    0.000350    0.000050       0.00100  \n",
       "75%        0.000200    0.000100    0.000525    0.000200       0.00130  \n",
       "max        0.001700    0.000700    0.001600    0.000800       0.00280  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_tax = get_error_rates_df(df_buggy, model)\n",
    "err_tax.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_mean_cross_entropy(df: pd.DataFrame, model: Model, n: Optional[int] = None):\n",
    "    \"\"\"\n",
    "    Get the mean cross entropy for a model on an entire pandas dataframe\n",
    "\n",
    "    :param df: the pandas dataframe containing each method to have the model predict on\n",
    "    :param model: the model used to generate the predictions\n",
    "    :param n: the number of methods to evaluate. If none, the entire dataframe will be used\n",
    "    :returns: returns the mean cross entropy of the models predictions compared to true labels\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        n = len(df)\n",
    "\n",
    "    cross_entropy_losses = []\n",
    "    # Need to change to sparse_categorical_crossentropy\n",
    "    for mthd in df.code.values[:n]:\n",
    "        # token the method and get the probabilities for each token from the model\n",
    "        inputs = model.tokenize(mthd)\n",
    "        probs = model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "        # calculate the cross entropy between the labels and probabilities\n",
    "        losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            inputs[\"input_ids\"], probs\n",
    "        ).numpy()\n",
    "        cross_entropy_losses.append(losses)\n",
    "\n",
    "    # flatten list of cross entropies and calculate the mean, median, std, and mad\n",
    "    cross_entropy_losses = np.concatenate(cross_entropy_losses)\n",
    "    return {\n",
    "        \"mean\": np.mean(cross_entropy_losses),\n",
    "        \"median\": np.median(cross_entropy_losses),\n",
    "        \"std\": np.std(cross_entropy_losses),\n",
    "        \"mad\": stats.median_abs_deviation(cross_entropy_losses),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_losses = []\n",
    "for mthd in df_fake.code.values:\n",
    "    inputs = gru_model.tokenize(mthd)\n",
    "    probs = gru_model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "    losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        inputs[\"input_ids\"], probs\n",
    "    ).numpy()\n",
    "    cross_entropy_losses.append(losses)\n",
    "\n",
    "CROSS_ENTROPY_MEAN = np.mean(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_MEDIAN = np.median(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_STD = np.std(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_MAD = stats.median_abs_deviation(np.concatenate(cross_entropy_losses))\n",
    "cross_entropy = get_mean_cross_entropy(df_fake, gru_model)\n",
    "\n",
    "assert np.isclose(CROSS_ENTROPY_MEAN, cross_entropy[\"mean\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_MEDIAN, cross_entropy[\"median\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_STD, cross_entropy[\"std\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_MAD, cross_entropy[\"mad\"], atol=1.0e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_losses = []\n",
    "for mthd in df_fake.code.values:\n",
    "    inputs = trnsfr_model.tokenize(mthd)\n",
    "    probs = trnsfr_model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "    losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        inputs[\"input_ids\"], probs\n",
    "    ).numpy()\n",
    "    cross_entropy_losses.append(losses)\n",
    "\n",
    "CROSS_ENTROPY_MEAN = np.mean(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_MEDIAN = np.median(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_STD = np.std(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_MAD = stats.median_abs_deviation(np.concatenate(cross_entropy_losses))\n",
    "cross_entropy = get_mean_cross_entropy(df_fake, trnsfr_model)\n",
    "\n",
    "assert np.isclose(CROSS_ENTROPY_MEAN, cross_entropy[\"mean\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_MEDIAN, cross_entropy[\"median\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_STD, cross_entropy[\"std\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_MAD, cross_entropy[\"mad\"], atol=1.0e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_mean_cross_entropy_df(df: pd.DataFrame, model: Model, bs = 16, n: Optional[int] = None):\n",
    "    \"\"\"\n",
    "    Get the mean cross entropy for a model on an entire pandas dataframe\n",
    "\n",
    "    :param df: the pandas dataframe containing each method to have the model predict on\n",
    "    :param model: the model used to generate the predictions\n",
    "    :param n: the number of methods to evaluate. If none, the entire dataframe will be used\n",
    "    :returns: returns the mean cross entropy of the models predictions compared to true labels\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        n = len(df)\n",
    "\n",
    "    cross_entropy_losses = []\n",
    "    for i in range(0, n, bs):\n",
    "        batch = [\"<sos>\" + mthd for mthd in df.code.values[i:i + bs]]\n",
    "        # token the method and get the probabilities for each token from the model\n",
    "        inputs = tf.stack([x.ids for x in model.tokenizer.encode_batch(batch)], axis = 0)\n",
    "        logits = model.model(inputs)\n",
    "        probs = tf.nn.softmax(logits).numpy()\n",
    "\n",
    "        # calculate the cross entropy between the labels and probabilities\n",
    "        losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            inputs, probs\n",
    "        ).numpy()\n",
    "        cross_entropy_losses.extend(np.mean(losses, axis = 1))\n",
    "    \n",
    "    new_df = pd.DataFrame(\n",
    "        zip(df.code.values[:n], cross_entropy_losses),\n",
    "        columns=[\"code\", \"y_cross_entropy\"]\n",
    "    )\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bugfix_path = Path(\"/home/jovyan/work/dvc-icodegen/datasets/controlled/testbeds/_ts_bug_fix\")\n",
    "df_buggy = pd.read_json(bugfix_path / \"buggy.jsonl\", orient=\"records\", lines=True)[\n",
    "    :10\n",
    "]\n",
    "model = RNNModel.from_path(\"/home/jovyan/work/dvc-icodegen/models/controlled/rnns/rnn_layers1_vocab10000_embed256_units1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_cross_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.607144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.313763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.711073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.687577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.793782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.330061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.028292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_cross_entropy\n",
       "count        10.000000\n",
       "mean          5.607144\n",
       "std           1.313763\n",
       "min           3.711073\n",
       "25%           4.687577\n",
       "50%           5.793782\n",
       "75%           6.330061\n",
       "max           8.028292"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy = get_mean_cross_entropy_df(df_buggy, model)\n",
    "cross_entropy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shapes of all inputs must match: values[0].shape = [23] != values[1].shape = [13] [Op:Pack]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0d279113ccbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mean_cross_entropy_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgru_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-24d9cb9203e7>\u001b[0m in \u001b[0;36mget_mean_cross_entropy_df\u001b[0;34m(df, model, bs, n)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"<sos>\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmthd\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmthd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# token the method and get the probabilities for each token from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1410\u001b[0m                        (axis, -expanded_num_dims, expanded_num_dims))\n\u001b[1;32m   1411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   6382\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6383\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6384\u001b[0;31m       return pack_eager_fallback(\n\u001b[0m\u001b[1;32m   6385\u001b[0m           values, axis=axis, name=name, ctx=_ctx)\n\u001b[1;32m   6386\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mpack_eager_fallback\u001b[0;34m(values, axis, name, ctx)\u001b[0m\n\u001b[1;32m   6422\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6423\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"N\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"axis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6424\u001b[0;31m   _result = _execute.execute(b\"Pack\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0m\u001b[1;32m   6425\u001b[0m                              ctx=ctx, name=name)\n\u001b[1;32m   6426\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes of all inputs must match: values[0].shape = [23] != values[1].shape = [13] [Op:Pack]"
     ]
    }
   ],
   "source": [
    "cross_entropy = get_mean_cross_entropy_df(df_fake, gru_model)\n",
    "cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "_TRANSFORMs = {\n",
    "#     \"randomized_tokens\": code_token_randomizer,\n",
    "#     \"randomized_lines\": line_randomizer,\n",
    "    \"comments_removed\": java_comment_remover,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[False, True] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/dvc-icodegen/models/controlled/rnns/rnn_layers1_vocab10000_embed256_units1024\n",
      "/home/jovyan/work/dvc-icodegen/models/controlled/rnns/gru_layers1_vocab10000_embed256_units512\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "def _get_metrics(df, model):\n",
    "#     mean_probs = get_mean_probs(df, model)\n",
    "    error_taxonomy_df = get_error_rates_df(df, model)\n",
    "#     df_dist = mean_dist_probs(df, model)\n",
    "    mean_cross_entropy_df = get_mean_cross_entropy_df(df, model)\n",
    "\n",
    "    return {\n",
    "        \"error_taxonomy\": error_taxonomy_df,\n",
    "#         \"dist_mean\": df_dist,\n",
    "        \"mean_cross_entropy\": mean_cross_entropy_df,\n",
    "    }\n",
    "\n",
    "\n",
    "# def _long_range(data_dir, model, n=None):\n",
    "#     long_range_results = {}\n",
    "\n",
    "#     df_buggy = pd.read_json(data_dir / \"buggy.jsonl\", orient=\"records\", lines=True)[:n]\n",
    "#     long_range_results[\"buggy\"] = _get_metrics(df_buggy, model)\n",
    "#     del df_buggy\n",
    "\n",
    "#     df_fixed = pd.read_json(data_dir / \"fixed.jsonl\", orient=\"records\", lines=True)[:n]\n",
    "#     long_range_results[\"fixed\"] = _get_metrics(df_fixed, model)\n",
    "#     del df_fixed\n",
    "\n",
    "#     df_codesearchnet = pd.read_json(\n",
    "#         data_dir / \"codesearchnet_java\" / \"test.jsonl\", orient=\"records\", lines=True\n",
    "#     )[:n]\n",
    "#     long_range_results[\"codesearchnet_original\"] = _get_metrics(df_codesearchnet, model)\n",
    "\n",
    "#     for transform in _TRANSFORMs:\n",
    "#         df_transformed = transform_df(df_codesearchnet, _TRANSFORMs[transform])\n",
    "#         long_range_results[\"codesearchnet_\" + transform] = _get_metrics(\n",
    "#             df_transformed, model\n",
    "#         )\n",
    "#         del df_transformed\n",
    "\n",
    "#     return long_range_results\n",
    "\n",
    "\n",
    "def _long_range(bigclone_path, bugfix_path, codesearchnet_path, model, out_path, n=None):\n",
    "    long_range_results = {}\n",
    "\n",
    "    # TODO add bigclone data\n",
    "\n",
    "    df_buggy = pd.read_json(bugfix_path / \"buggy.jsonl\", orient=\"records\", lines=True)[\n",
    "        :n\n",
    "    ]\n",
    "    buggy_metrics = _get_metrics(df_buggy, model)\n",
    "\n",
    "    df_fixed = pd.read_json(bugfix_path / \"fixed.jsonl\", orient=\"records\", lines=True)[\n",
    "        :n\n",
    "    ]\n",
    "    fixed_metrics = _get_metrics(df_fixed, model)\n",
    "    \n",
    "    bug_fix_err_df = pd.concat(\n",
    "        [buggy_metrics[\"error_taxonomy\"], fixed_metrics[\"error_taxonomy\"]]\n",
    "    ).sort_index().reset_index(drop=True)\n",
    "    bug_fix_err_df[\"x_treatment\"] = [False, True] * len(buggy_metrics[\"error_taxonomy\"])\n",
    "    bug_fix_err_df.to_json(out_path / \"bug_fix_error_taxonomy.jsonl\", orient=\"records\", lines=True)\n",
    "    \n",
    "    bug_fix_cross_df = pd.concat(\n",
    "        [buggy_metrics[\"mean_cross_entropy\"], fixed_metrics[\"mean_cross_entropy\"]]\n",
    "    ).sort_index().reset_index(drop=True)\n",
    "    bug_fix_cross_df[\"x_treatment\"] = [False, True] * len(buggy_metrics[\"mean_cross_entropy\"])\n",
    "    bug_fix_cross_df.to_json(out_path / \"bug_fix_cross_entropy.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "#     df_codesearchnet = pd.read_json(\n",
    "#         codesearchnet_path / \"codesearchnet_java\" / \"test.jsonl\",\n",
    "#         orient=\"records\",\n",
    "#         lines=True,\n",
    "#     )[:n]\n",
    "#     long_range_results[\"codesearchnet_original\"] = _get_metrics(df_codesearchnet, model)\n",
    "\n",
    "#     for transform in _TRANSFORMs:\n",
    "#         df_transformed = transform_df(df_codesearchnet, _TRANSFORMs[transform])\n",
    "#         long_range_results[\"codesearchnet_\" + transform] = _get_metrics(\n",
    "#             df_transformed, model\n",
    "#         )\n",
    "\n",
    "    return long_range_results\n",
    "\n",
    "\n",
    "def _counterfactual(control_results, treatment_results):\n",
    "    pass\n",
    "\n",
    "\n",
    "def evaluate(data_path, model_path):\n",
    "    \"\"\"Function for evaluating models related to the library.\"\"\"\n",
    "    results = defaultdict(dict)\n",
    "    testbed_path = data_path / \"controlled/testbeds\"\n",
    "    #     models = []\n",
    "    # These model folders will need to contain the config of the model as well\n",
    "    # to differentiate them\n",
    "    for m_path in model_path.glob(\"*/\"):\n",
    "        model = None\n",
    "        print(m_path)\n",
    "        model = RNNModel.from_path(m_path)\n",
    "#         if m_path.name == \"Transformer\":\n",
    "#             model = TransformerModel.from_path(m_path)\n",
    "#         elif \"rnn\" in m_path.name:\n",
    "#             model = RNNModel.from_path(m_path)\n",
    "#         elif m_path.name == \"RNN\":\n",
    "#             pass\n",
    "#         return model\n",
    "    \n",
    "        bigclone_path = testbed_path / \"_ts_bigclone_types\"\n",
    "        bugfix_path = testbed_path / \"_ts_bug_fix\"\n",
    "        codesearchnet_path = testbed_path / \"codesearchnet\"\n",
    "\n",
    "        # Long-Range Interactions\n",
    "#         results[m_path.name][\"long_range\"] = \n",
    "        _long_range(\n",
    "            bigclone_path, bugfix_path, codesearchnet_path, model, bugfix_path, n=10\n",
    "        )\n",
    "#     return dict(results)\n",
    "\n",
    "\n",
    "path = Path(\"/home/jovyan/work\")\n",
    "data_path = path / \"dvc-icodegen/datasets\"\n",
    "model_path = path / \"dvc-icodegen/models/controlled/rnns/\"\n",
    "results = evaluate(data_path, model_path)\n",
    "        # Long-Range Interactions\n",
    "#         results[m_path.name][\"long_range\"] = _long_range(\n",
    "#             bigclone_path, bugfix_path, codesearchnet_path, model\n",
    "#         )\n",
    "\n",
    "#     return results\n",
    "    # Counterfactuals\n",
    "\n",
    "\n",
    "#         results[m_path][\"counterfactual\"] = _counterfactual(data_dir, model)\n",
    "# _counterfactual(control_results, treatment_results)\n",
    "\n",
    "# Save results in json format\n",
    "# Long-Range Interactions\n",
    "#     long_range_results = _long_range(data_dir, models)\n",
    "#     long_range_results\n",
    "\n",
    "#     # Counterfactuals\n",
    "#     counterfactual_results = []\n",
    "#     counterfactual_results\n",
    "#     for transform in _TRANSFORMs:\n",
    "#         pass\n",
    "# _counterfactual(control_results, treatment_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gru_layers1_vocab10000_embed256_units512': {'long_range': {'buggy': {'error_taxonomy': {'blocks': {'<{>': {'error_rate': 1.0,\n",
       "       'count': 28},\n",
       "      '<}>': {'error_rate': 1.0, 'count': 28},\n",
       "      '<[>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<]>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<(>': {'error_rate': 1.0, 'count': 82},\n",
       "      '<)>': {'error_rate': 0.8658536585365854, 'count': 82},\n",
       "      '<;>': {'error_rate': 1.0, 'count': 53},\n",
       "      '<return>': {'error_rate': 1.0, 'count': 12},\n",
       "      'stats': {'mean_error_rate': 0.9832317073170731,\n",
       "       'stdev_error_rate': 0.04436473235016844,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'exceptions': {'<catch>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<try>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<finally>': {'error_rate': nan, 'count': 0},\n",
       "      '<throw>': {'error_rate': nan, 'count': 0},\n",
       "      '<throws>': {'error_rate': 1.0, 'count': 1},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'oop': {'<class>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<instanceof>': {'error_rate': nan, 'count': 0},\n",
       "      '<interface>': {'error_rate': nan, 'count': 0},\n",
       "      '<private>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<protected>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<public>': {'error_rate': 1.0, 'count': 5},\n",
       "      '<abstract>': {'error_rate': nan, 'count': 0},\n",
       "      '<extends>': {'error_rate': nan, 'count': 0},\n",
       "      '<package>': {'error_rate': nan, 'count': 0},\n",
       "      '<this>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<implements>': {'error_rate': nan, 'count': 0},\n",
       "      '<import>': {'error_rate': nan, 'count': 0},\n",
       "      '<new>': {'error_rate': 1.0, 'count': 6},\n",
       "      '<super>': {'error_rate': 1.0, 'count': 2},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'tests': {'<assert>': {'error_rate': 1.0, 'count': 2},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'declarations': {'<native>': {'error_rate': nan, 'count': 0},\n",
       "      '<static>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<synchronized>': {'error_rate': nan, 'count': 0},\n",
       "      '<transient>': {'error_rate': nan, 'count': 0},\n",
       "      '<volatile>': {'error_rate': nan, 'count': 0},\n",
       "      '<void>': {'error_rate': 1.0, 'count': 7},\n",
       "      '<final>': {'error_rate': nan, 'count': 0},\n",
       "      '<enum>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'conditionals': {'<else>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<if>': {'error_rate': 1.0, 'count': 12},\n",
       "      '<switch>': {'error_rate': nan, 'count': 0},\n",
       "      '<case>': {'error_rate': nan, 'count': 0},\n",
       "      '<default>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'loops': {'<break>': {'error_rate': nan, 'count': 0},\n",
       "      '<do>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<for>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<while>': {'error_rate': nan, 'count': 0},\n",
       "      '<continue>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'operators': {'<=>': {'error_rate': 1.0, 'count': 17},\n",
       "      '<+>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<->': {'error_rate': 1.0, 'count': 1},\n",
       "      '<*>': {'error_rate': 1.0, 'count': 2},\n",
       "      '</>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<%>': {'error_rate': nan, 'count': 0},\n",
       "      '<++>': {'error_rate': nan, 'count': 0},\n",
       "      '<-->': {'error_rate': nan, 'count': 0},\n",
       "      '<!>': {'error_rate': 1.0, 'count': 5},\n",
       "      '<==>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<!=>': {'error_rate': 1.0, 'count': 2},\n",
       "      '<greater_equal>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<lesser_equal>': {'error_rate': nan, 'count': 0},\n",
       "      '<&&>': {'error_rate': nan, 'count': 0},\n",
       "      '<||>': {'error_rate': nan, 'count': 0},\n",
       "      '<?>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<:>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<~>': {'error_rate': nan, 'count': 0},\n",
       "      '<double_lesser>': {'error_rate': nan, 'count': 0},\n",
       "      '<double_greater>': {'error_rate': nan, 'count': 0},\n",
       "      '<triple_greater>': {'error_rate': nan, 'count': 0},\n",
       "      '<&>': {'error_rate': nan, 'count': 0},\n",
       "      '<^>': {'error_rate': nan, 'count': 0},\n",
       "      '<|>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'datatypes': {'<byte>': {'error_rate': nan, 'count': 0},\n",
       "      '<char>': {'error_rate': nan, 'count': 0},\n",
       "      '<float>': {'error_rate': nan, 'count': 0},\n",
       "      '<boolean>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<double>': {'error_rate': nan, 'count': 0},\n",
       "      '<int>': {'error_rate': 1.0, 'count': 14},\n",
       "      '<long>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<short>': {'error_rate': nan, 'count': 0},\n",
       "      '<strictfp>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'extra_tokens': {'<@>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<...>': {'error_rate': nan, 'count': 0},\n",
       "      '<null>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<true>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<false>': {'error_rate': nan, 'count': 0},\n",
       "      '<n>': {'error_rate': 1.0, 'count': 100},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}}},\n",
       "    'dist_mean':     dist     mean_prob  std_prob      med_prob  mad_prob\n",
       "    0      8  1.207141e-07  0.000000  1.207141e-07  0.000000\n",
       "    1     12  3.133740e-05  0.000000  3.133740e-05  0.000000\n",
       "    2     14  3.254278e-04  0.000000  3.254278e-04  0.000000\n",
       "    3     16  4.908312e-06  0.000002  4.908312e-06  0.000002\n",
       "    4     18  4.721369e-07  0.000000  4.721369e-07  0.000000\n",
       "    5     21  2.520642e-06  0.000000  2.520642e-06  0.000000\n",
       "    6     41  6.837193e-05  0.000000  6.837193e-05  0.000000\n",
       "    7     45  9.986493e-07  0.000000  9.986493e-07  0.000000\n",
       "    8     47  5.149367e-06  0.000000  5.149367e-06  0.000000\n",
       "    9     55  1.139350e-06  0.000000  1.139350e-06  0.000000\n",
       "    10    57  8.800810e-06  0.000000  8.800810e-06  0.000000\n",
       "    11    73  1.652192e-04  0.000000  1.652192e-04  0.000000\n",
       "    12    76  1.724610e-06  0.000000  1.724610e-06  0.000000\n",
       "    13    87  6.410999e-02  0.000000  6.410999e-02  0.000000\n",
       "    14    95  1.246914e-05  0.000000  1.246914e-05  0.000000\n",
       "    15    98  5.602366e-02  0.000000  5.602366e-02  0.000000\n",
       "    16    99  2.577458e-04  0.000000  2.577458e-04  0.000000\n",
       "    17   101  2.184061e-04  0.000000  2.184061e-04  0.000000\n",
       "    18   130  4.229159e-02  0.000000  4.229159e-02  0.000000\n",
       "    19   148  3.150251e-02  0.000000  3.150251e-02  0.000000\n",
       "    20   159  3.104646e-02  0.000000  3.104646e-02  0.000000\n",
       "    21   171  5.248478e-03  0.000000  5.248478e-03  0.000000\n",
       "    22   173  1.191561e-01  0.000000  1.191561e-01  0.000000\n",
       "    23   216  7.951981e-04  0.000000  7.951981e-04  0.000000,\n",
       "    'mean_cross_entropy': {'mean': 9.728883,\n",
       "     'median': 9.318403,\n",
       "     'std': 2.71132,\n",
       "     'mad': 0.3798942565917969}},\n",
       "   'fixed': {'error_taxonomy': {'blocks': {'<{>': {'error_rate': 1.0,\n",
       "       'count': 28},\n",
       "      '<}>': {'error_rate': 1.0, 'count': 28},\n",
       "      '<[>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<]>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<(>': {'error_rate': 1.0, 'count': 82},\n",
       "      '<)>': {'error_rate': 0.8658536585365854, 'count': 82},\n",
       "      '<;>': {'error_rate': 1.0, 'count': 53},\n",
       "      '<return>': {'error_rate': 1.0, 'count': 12},\n",
       "      'stats': {'mean_error_rate': 0.9832317073170731,\n",
       "       'stdev_error_rate': 0.04436473235016844,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'exceptions': {'<catch>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<try>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<finally>': {'error_rate': nan, 'count': 0},\n",
       "      '<throw>': {'error_rate': nan, 'count': 0},\n",
       "      '<throws>': {'error_rate': 1.0, 'count': 1},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'oop': {'<class>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<instanceof>': {'error_rate': nan, 'count': 0},\n",
       "      '<interface>': {'error_rate': nan, 'count': 0},\n",
       "      '<private>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<protected>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<public>': {'error_rate': 1.0, 'count': 5},\n",
       "      '<abstract>': {'error_rate': nan, 'count': 0},\n",
       "      '<extends>': {'error_rate': nan, 'count': 0},\n",
       "      '<package>': {'error_rate': nan, 'count': 0},\n",
       "      '<this>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<implements>': {'error_rate': nan, 'count': 0},\n",
       "      '<import>': {'error_rate': nan, 'count': 0},\n",
       "      '<new>': {'error_rate': 1.0, 'count': 6},\n",
       "      '<super>': {'error_rate': 1.0, 'count': 2},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'tests': {'<assert>': {'error_rate': 1.0, 'count': 2},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'declarations': {'<native>': {'error_rate': nan, 'count': 0},\n",
       "      '<static>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<synchronized>': {'error_rate': nan, 'count': 0},\n",
       "      '<transient>': {'error_rate': nan, 'count': 0},\n",
       "      '<volatile>': {'error_rate': nan, 'count': 0},\n",
       "      '<void>': {'error_rate': 1.0, 'count': 7},\n",
       "      '<final>': {'error_rate': nan, 'count': 0},\n",
       "      '<enum>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'conditionals': {'<else>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<if>': {'error_rate': 1.0, 'count': 12},\n",
       "      '<switch>': {'error_rate': nan, 'count': 0},\n",
       "      '<case>': {'error_rate': nan, 'count': 0},\n",
       "      '<default>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'loops': {'<break>': {'error_rate': nan, 'count': 0},\n",
       "      '<do>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<for>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<while>': {'error_rate': nan, 'count': 0},\n",
       "      '<continue>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'operators': {'<=>': {'error_rate': 1.0, 'count': 17},\n",
       "      '<+>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<->': {'error_rate': 1.0, 'count': 1},\n",
       "      '<*>': {'error_rate': 1.0, 'count': 2},\n",
       "      '</>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<%>': {'error_rate': nan, 'count': 0},\n",
       "      '<++>': {'error_rate': nan, 'count': 0},\n",
       "      '<-->': {'error_rate': nan, 'count': 0},\n",
       "      '<!>': {'error_rate': 1.0, 'count': 5},\n",
       "      '<==>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<!=>': {'error_rate': 1.0, 'count': 2},\n",
       "      '<greater_equal>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<lesser_equal>': {'error_rate': nan, 'count': 0},\n",
       "      '<&&>': {'error_rate': nan, 'count': 0},\n",
       "      '<||>': {'error_rate': nan, 'count': 0},\n",
       "      '<?>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<:>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<~>': {'error_rate': nan, 'count': 0},\n",
       "      '<double_lesser>': {'error_rate': nan, 'count': 0},\n",
       "      '<double_greater>': {'error_rate': nan, 'count': 0},\n",
       "      '<triple_greater>': {'error_rate': nan, 'count': 0},\n",
       "      '<&>': {'error_rate': nan, 'count': 0},\n",
       "      '<^>': {'error_rate': nan, 'count': 0},\n",
       "      '<|>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'datatypes': {'<byte>': {'error_rate': nan, 'count': 0},\n",
       "      '<char>': {'error_rate': nan, 'count': 0},\n",
       "      '<float>': {'error_rate': nan, 'count': 0},\n",
       "      '<boolean>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<double>': {'error_rate': nan, 'count': 0},\n",
       "      '<int>': {'error_rate': 1.0, 'count': 14},\n",
       "      '<long>': {'error_rate': 1.0, 'count': 1},\n",
       "      '<short>': {'error_rate': nan, 'count': 0},\n",
       "      '<strictfp>': {'error_rate': nan, 'count': 0},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}},\n",
       "     'extra_tokens': {'<@>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<...>': {'error_rate': nan, 'count': 0},\n",
       "      '<null>': {'error_rate': 1.0, 'count': 3},\n",
       "      '<true>': {'error_rate': 1.0, 'count': 4},\n",
       "      '<false>': {'error_rate': nan, 'count': 0},\n",
       "      '<n>': {'error_rate': 1.0, 'count': 100},\n",
       "      'stats': {'mean_error_rate': 1.0,\n",
       "       'stdev_error_rate': 0.0,\n",
       "       'median_error_rate': 1.0,\n",
       "       'mad_error_rate': 0.0}}},\n",
       "    'dist_mean':     dist     mean_prob  std_prob      med_prob  mad_prob\n",
       "    0      8  2.514261e-06  0.000002  2.514261e-06  0.000002\n",
       "    1     12  3.133740e-05  0.000000  3.133740e-05  0.000000\n",
       "    2     14  3.254278e-04  0.000000  3.254278e-04  0.000000\n",
       "    3     16  2.813610e-06  0.000000  2.813610e-06  0.000000\n",
       "    4     18  4.721369e-07  0.000000  4.721369e-07  0.000000\n",
       "    5     21  3.923531e-06  0.000001  3.923531e-06  0.000001\n",
       "    6     41  6.837193e-05  0.000000  6.837193e-05  0.000000\n",
       "    7     47  5.149367e-06  0.000000  5.149367e-06  0.000000\n",
       "    8     50  1.426494e-06  0.000000  1.426494e-06  0.000000\n",
       "    9     55  1.139350e-06  0.000000  1.139350e-06  0.000000\n",
       "    10    57  8.800810e-06  0.000000  8.800810e-06  0.000000\n",
       "    11    76  1.724610e-06  0.000000  1.724610e-06  0.000000\n",
       "    12    87  6.347100e-02  0.000000  6.347100e-02  0.000000\n",
       "    13    94  1.502765e-02  0.014779  1.502765e-02  0.014779\n",
       "    14    95  1.327239e-05  0.000000  1.327239e-05  0.000000\n",
       "    15    99  3.265051e-05  0.000000  3.265051e-05  0.000000\n",
       "    16   104  4.238477e-04  0.000000  4.238477e-04  0.000000\n",
       "    17   135  4.673224e-02  0.000000  4.673224e-02  0.000000\n",
       "    18   148  2.086460e-01  0.000000  2.086460e-01  0.000000\n",
       "    19   156  2.981598e-02  0.000000  2.981598e-02  0.000000\n",
       "    20   159  3.092586e-02  0.000000  3.092586e-02  0.000000\n",
       "    21   171  5.079383e-03  0.000000  5.079383e-03  0.000000\n",
       "    22   222  1.679451e-04  0.000000  1.679451e-04  0.000000,\n",
       "    'mean_cross_entropy': {'mean': 9.721969,\n",
       "     'median': 9.318403,\n",
       "     'std': 2.6962547,\n",
       "     'mad': 0.35593461990356445}}}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_range_results = _long_range(Path(\"/tmp\"), model, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_data.core.ipynb.\n",
      "Converted 01_data.transforms.ipynb.\n",
      "Converted 02_model.core.ipynb.\n",
      "Converted 04_evaluation.core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
