{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp evaluation.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from icodegen.data.transforms import (\n",
    "    code_token_randomizer,\n",
    "    line_randomizer,\n",
    "    java_comment_remover,\n",
    "    transform_df,\n",
    ")\n",
    "from icodegen.model.core import Model, RNNModel\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from typing import Dict, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at sshleifer/tiny-gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# Setting up testing data\n",
    "from transformers import GPT2TokenizerFast, TFGPT2LMHeadModel\n",
    "from icodegen.model.core import TransformerModel, RNNModel\n",
    "\n",
    "# Using tiny-gpt2 for just quick tests since it is... tiny :)\n",
    "trnsfr_tokenizer = GPT2TokenizerFast.from_pretrained(\"sshleifer/tiny-gpt2\")\n",
    "tokenizer = trnsfr_tokenizer.backend_tokenizer\n",
    "trnsfr = TFGPT2LMHeadModel.from_pretrained(\"sshleifer/tiny-gpt2\")\n",
    "trnsfr_model = TransformerModel(tokenizer, trnsfr)\n",
    "\n",
    "rnn_type = \"gru\"\n",
    "n_layers = 1\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "embedding_dim = 128\n",
    "rnn_units = 128\n",
    "batch_size = 1\n",
    "out_path = \"/tmp\"\n",
    "gru_model = RNNModel(\n",
    "    rnn_type,\n",
    "    n_layers,\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    rnn_units,\n",
    "    batch_size,\n",
    "    out_path,\n",
    "    tokenizer,\n",
    ")\n",
    "\n",
    "df_fake = pd.DataFrame(\n",
    "    [\"aaaa(bb(aaaa(bb()()ccc)dd)()ccc)dd\", \"aaaa(bb()ccccc)dd\"], columns=[\"code\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaa(bb(aaaa(bb()()ccc)dd)()ccc)dd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaaa(bb()ccccc)dd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 code\n",
       "0  aaaa(bb(aaaa(bb()()ccc)dd)()ccc)dd\n",
       "1                   aaaa(bb()ccccc)dd"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_mean_probs(df: pd.DataFrame, model: Model, n: Optional[int] = None):\n",
    "    \"\"\"\n",
    "    Get the mean probability of each token that the model\n",
    "    should predict for an entire pandas dataframe.\n",
    "\n",
    "    :param df: the pandas dataframe containing each method to have the model predict on\n",
    "    :param model: the model used to generate the predictions\n",
    "    :param n: the number of methods to evaluate. If none, the entire dataframe will be used\n",
    "    :returns: returns a numpy array of the mean probability for each token in the model's vocab\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        n = len(df)\n",
    "\n",
    "    # setup container lists for the number of occurrences and sum of probabilities for each token\n",
    "    counts = [0] * model.tokenizer.get_vocab_size()\n",
    "    sum_probs = [0.0] * model.tokenizer.get_vocab_size()\n",
    "    # loop through each method\n",
    "    for mthd in df.code.values[:n]:\n",
    "        # token the method and generate the probabilities for the model's predictions\n",
    "        inputs = model.tokenize(mthd)\n",
    "        probs = model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "        # loop through each token and its probability and update the container lists\n",
    "        for idx, p in zip(inputs[\"input_ids\"][0], probs):\n",
    "            counts[idx] += 1\n",
    "            sum_probs[idx] += p[idx]\n",
    "\n",
    "    # convert the lists to numpy lists and perform element wise division to get the mean probabilities for each token\n",
    "    counts = np.array(counts)\n",
    "    sum_probs = np.array(sum_probs)\n",
    "\n",
    "    # perform division, but not when denominator is zero. In those cases, just leave value as NAN.\n",
    "    nans = np.empty(counts.shape)\n",
    "    nans.fill(np.nan)\n",
    "    mean_probs = np.divide(sum_probs, counts, out=nans, where=counts != 0)\n",
    "    # TODO: convert to dictionary with keys as tokens\n",
    "    mean_probs = {\n",
    "        model.tokenizer.id_to_token(i): mean_probs[i] for i in range(len(mean_probs))\n",
    "    }\n",
    "    return mean_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_NAN_PROBS_MEAN = np.array(\n",
    "    [\n",
    "        2.01237513e-05,\n",
    "        1.98944481e-05,\n",
    "        2.01449202e-05,\n",
    "        2.04353437e-05,\n",
    "        2.02043060e-05,\n",
    "        2.02826177e-05,\n",
    "        2.09888076e-05,\n",
    "        2.07051467e-05,\n",
    "        1.98100976e-05,\n",
    "        2.02152678e-05,\n",
    "        2.02035244e-05,\n",
    "        2.10283021e-05,\n",
    "    ]\n",
    ")\n",
    "\n",
    "mean_probs = np.array(list(get_mean_probs(df_fake, trnsfr_model).values()))\n",
    "non_nan_idx = np.argwhere(~np.isnan(mean_probs)).flatten()\n",
    "non_nan_mean_prob = mean_probs[non_nan_idx]\n",
    "\n",
    "assert np.isclose(non_nan_mean_prob, NON_NAN_PROBS_MEAN, atol=1.0e-6).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_NAN_PROBS_MEAN = np.array(\n",
    "    [\n",
    "        1.99270412e-05,\n",
    "        1.99168703e-05,\n",
    "        1.98815596e-05,\n",
    "        1.99057849e-05,\n",
    "        1.98800869e-05,\n",
    "        1.98893995e-05,\n",
    "        1.98797388e-05,\n",
    "        1.98960342e-05,\n",
    "        1.99086674e-05,\n",
    "        1.98605580e-05,\n",
    "        1.98807957e-05,\n",
    "        1.98842057e-05,\n",
    "    ]\n",
    ")\n",
    "\n",
    "mean_probs = np.array(list(get_mean_probs(df_fake, gru_model).values()))\n",
    "non_nan_idx = np.argwhere(~np.isnan(mean_probs)).flatten()\n",
    "non_nan_mean_prob = mean_probs[non_nan_idx]\n",
    "\n",
    "assert np.isclose(non_nan_mean_prob, NON_NAN_PROBS_MEAN, atol=1.0e-6).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def find_parens(toks: List[str], opening: str, closing: str) -> Dict[int, int]:\n",
    "    \"\"\"\n",
    "    Get the indices for the opening and closing tokens.\n",
    "    From https://stackoverflow.com/a/29992065/5768407\n",
    "    by user Baltasarq (https://stackoverflow.com/users/266978/baltasarq).\n",
    "\n",
    "    :param toks: the tokenized version of a method\n",
    "    :param opening: the opening token that will be matched against the closing token\n",
    "    :param closing: the closing token that will be matched against the opening token\n",
    "    :returns: returns a dictionary with the opening token indices as the keys and the closing token indices as the values\n",
    "    \"\"\"\n",
    "    toret = {}\n",
    "    pstack = []\n",
    "\n",
    "    for i, tok in enumerate(toks):\n",
    "        if tok == opening:\n",
    "            pstack.append(i)\n",
    "        elif tok == closing:\n",
    "            if len(pstack) == 0:\n",
    "                raise IndexError(\"No matching closing parens at: \" + str(i))\n",
    "            toret[pstack.pop()] = i\n",
    "\n",
    "    if len(pstack) > 0:\n",
    "        raise IndexError(\"No matching opening parens at: \" + str(pstack.pop()))\n",
    "\n",
    "    return toret\n",
    "\n",
    "\n",
    "def _get_dist_probs(\n",
    "    mthd: str, model: Model, opening: str, closing: str\n",
    ") -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Get the distances and mean probabilities between opening and closing tokens in a given method.\n",
    "\n",
    "    :param mthd: the method to get the ranges of the opening and closing tokens and their probabilities\n",
    "    :param model: the model used to generate the predictions\n",
    "    :param opening: the opening token used for calculating the distance between opening and closing tokens\n",
    "    :param closing: the closing token used for calculating the distance between opening and closing tokens as well as the token to get the mean probability of\n",
    "    :returns: returns a dictionary with the distance between the opening and closing tokens as keys and their mean probabilities as values\n",
    "    \"\"\"\n",
    "    # WARNING: Careful when using different tokenizers since HF tokenizers lib have diff API then HF transformers lib tokenizers... You will need to update this when using custom model and tokenizer...\n",
    "\n",
    "    # get the distances for the opening and closing tokens\n",
    "    toks = model.tokenizer.encode(mthd).tokens\n",
    "    idxs = find_parens(toks, opening, closing)\n",
    "\n",
    "    # get the model probabilities for the given method\n",
    "    inputs = model.tokenize(mthd)\n",
    "    probs = model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "    # sum up the probabilities of the different distances for the closing token\n",
    "    dist_probs = defaultdict(float)\n",
    "    for open_id, close_id in idxs.items():\n",
    "        dist_probs[close_id - open_id] += probs[close_id][\n",
    "            inputs[\"input_ids\"][0][close_id]\n",
    "        ]\n",
    "\n",
    "    # get the mean of the summed probabilities\n",
    "    dist_cnts = Counter([close_id - open_id for open_id, close_id in idxs.items()])\n",
    "    dist_probs = {dist: dist_probs[dist] / n for dist, n in dist_cnts.items()}\n",
    "    return dist_probs\n",
    "\n",
    "\n",
    "def mean_dist_probs(\n",
    "    df: pd.DataFrame,\n",
    "    model: Model,\n",
    "    opening: Optional[str] = \"<{>\",\n",
    "    closing: Optional[str] = \"<}>\",\n",
    "    n: Optional[int] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get the distance between opening and closing tokens and the mean probability of each closing token that the model should predict for an entire pandas dataframe.\n",
    "\n",
    "    :param df: the pandas dataframe containing each method to have the model predict on\n",
    "    :param model: the model used to generate the predictions\n",
    "    :param opening: the opening token used for calculating the distance between opening and closing tokens\n",
    "    :param closing: the closing token used for calculating the distance between opening and closing tokens as well as the token to get the mean probability of\n",
    "    :param n: the number of methods to evaluate. If none, the entire dataframe will be used\n",
    "    :returns: returns a dataframe with the distances between opening and closing tokens and their mean probabilities\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        n = len(df)\n",
    "\n",
    "    # get the probabilities for the different distances for an entire dataframe\n",
    "    df = df.iloc[:n].copy()\n",
    "    dist_probs = df.code.apply(\n",
    "        lambda mthd: _get_dist_probs(mthd, model, opening, closing)\n",
    "    ).values\n",
    "\n",
    "    # flatten the keys of the different distances into a list\n",
    "    dist_keys = []\n",
    "    for probs in dist_probs:\n",
    "        dist_keys.extend(probs.keys())\n",
    "    # merge dictionaries across methods by taking the mean of probs with the same distance. Modified from https://stackoverflow.com/a/10461916/5768407,\n",
    "    # users georg https://stackoverflow.com/users/989121/georg and Rémy Hosseinkhan Boucher https://stackoverflow.com/users/12149730/r%c3%a9my-hosseinkhan-boucher\n",
    "    mean_dist_probs = {\n",
    "        k: np.nanmean(np.array([probs.get(k, np.nan) for probs in dist_probs]))\n",
    "        for k in set(dist_keys)\n",
    "    }\n",
    "    std_dist_probs = {\n",
    "        k: np.nanstd(np.array([probs.get(k, np.nan) for probs in dist_probs]))\n",
    "        for k in set(dist_keys)\n",
    "    }\n",
    "\n",
    "    med_dist_probs = {\n",
    "        k: np.nanmedian(np.array([probs.get(k, np.nan) for probs in dist_probs]))\n",
    "        for k in set(dist_keys)\n",
    "    }\n",
    "    mad_dist_probs = {\n",
    "        k: stats.median_abs_deviation(\n",
    "            np.array([probs.get(k, np.nan) for probs in dist_probs]), nan_policy=\"omit\"\n",
    "        )\n",
    "        for k in set(dist_keys)\n",
    "    }\n",
    "    # TODO: convert to dictionary\n",
    "    df_dist = (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"dist\": list(mean_dist_probs.keys()),\n",
    "                \"mean_prob\": list(mean_dist_probs.values()),\n",
    "                \"std_prob\": list(std_dist_probs.values()),\n",
    "                \"med_prob\": list(med_dist_probs.values()),\n",
    "                \"mad_prob\": list(mad_dist_probs.values()),\n",
    "            }\n",
    "        )\n",
    "        .sort_values(\"dist\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return df_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIST_DF = pd.DataFrame(\n",
    "    {\n",
    "        \"dist\": [6, 10, 16],\n",
    "        \"mean_prob\": [\n",
    "            1.98822217e-05,\n",
    "            1.97613608e-05,\n",
    "            1.97816771e-05,\n",
    "        ],\n",
    "        \"std_prob\": [\n",
    "            4.93400876e-09,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "        ],\n",
    "        \"med_prob\": [\n",
    "            2.04683793e-05,\n",
    "            2.07205376e-05,\n",
    "            1.97817026e-05,\n",
    "        ],\n",
    "        \"mad_prob\": [\n",
    "            4.93400876e-09,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "df_dist = mean_dist_probs(df_fake, gru_model, opening=\"(\", closing=\")\")\n",
    "\n",
    "assert (DIST_DF.dist.values == df_dist.dist.values).all()\n",
    "assert np.isclose(DIST_DF.mean_prob.values, df_dist.mean_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.std_prob.values, df_dist.std_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.med_prob.values, df_dist.med_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.mad_prob.values, df_dist.mad_prob.values, atol=1.0e-6).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIST_DF = pd.DataFrame(\n",
    "    {\n",
    "        \"dist\": [6, 10, 16],\n",
    "        \"mean_prob\": [\n",
    "            1.98822217e-05,\n",
    "            1.97613608e-05,\n",
    "            1.97816771e-05,\n",
    "        ],\n",
    "        \"std_prob\": [\n",
    "            4.93400876e-09,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "        ],\n",
    "        \"med_prob\": [\n",
    "            2.04683793e-05,\n",
    "            2.07205376e-05,\n",
    "            1.97817026e-05,\n",
    "        ],\n",
    "        \"mad_prob\": [\n",
    "            4.93400876e-09,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "df_dist = mean_dist_probs(df_fake, trnsfr_model, opening=\"(\", closing=\")\")\n",
    "\n",
    "assert (DIST_DF.dist.values == df_dist.dist.values).all()\n",
    "assert np.isclose(DIST_DF.mean_prob.values, df_dist.mean_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.std_prob.values, df_dist.std_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.med_prob.values, df_dist.med_prob.values, atol=1.0e-6).all()\n",
    "assert np.isclose(DIST_DF.mad_prob.values, df_dist.mad_prob.values, atol=1.0e-6).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_rates():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Need to move all these visualizations to their own module...\n",
    "# TODO: make this binning process easier where I can just pass in some vars and it handles it for me\n",
    "# df_dist[\"bin\"] = pd.cut(\n",
    "#     df_dist.dist, bins=[0, 10, 20], labels=[\"0-10\", \"11-20\"], include_lowest=True\n",
    "# )\n",
    "# df_dist = df_dist.sort_values(\"dist\")\n",
    "\n",
    "# bars = {}\n",
    "# for x in df_dist.bin.unique():\n",
    "#     bars[x] = sum(df_dist.loc[df_dist.bin == x].mean_prob.values)\n",
    "\n",
    "# plt.bar(bars.keys(), bars.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_mean_cross_entropy(df: pd.DataFrame, model: Model, n: Optional[int] = None):\n",
    "    \"\"\"\n",
    "    Get the mean cross entropy for a model on an entire pandas dataframe\n",
    "\n",
    "    :param df: the pandas dataframe containing each method to have the model predict on\n",
    "    :param model: the model used to generate the predictions\n",
    "    :param n: the number of methods to evaluate. If none, the entire dataframe will be used\n",
    "    :returns: returns the mean cross entropy of the models predictions compared to true labels\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        n = len(df)\n",
    "\n",
    "    cross_entropy_losses = []\n",
    "    # Need to change to sparse_categorical_crossentropy\n",
    "    for mthd in df.code.values[:n]:\n",
    "        # token the method and get the probabilities for each token from the model\n",
    "        inputs = model.tokenize(mthd)\n",
    "        probs = model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "        # calculate the cross entropy between the labels and probabilities\n",
    "        losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            inputs[\"input_ids\"], probs\n",
    "        ).numpy()\n",
    "        cross_entropy_losses.append(losses)\n",
    "\n",
    "    # flatten list of cross entropies and calculate the mean, median, std, and mad\n",
    "    cross_entropy_losses = np.concatenate(cross_entropy_losses)\n",
    "    return {\n",
    "        \"mean\": np.mean(cross_entropy_losses),\n",
    "        \"median\": np.median(cross_entropy_losses),\n",
    "        \"std\": np.std(cross_entropy_losses),\n",
    "        \"mad\": stats.median_abs_deviation(cross_entropy_losses),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_losses = []\n",
    "for mthd in df_fake.code.values:\n",
    "    inputs = gru_model.tokenize(mthd)\n",
    "    probs = gru_model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "    losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        inputs[\"input_ids\"], probs\n",
    "    ).numpy()\n",
    "    cross_entropy_losses.append(losses)\n",
    "\n",
    "CROSS_ENTROPY_MEAN = np.mean(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_MEDIAN = np.median(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_STD = np.std(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_MAD = stats.median_abs_deviation(np.concatenate(cross_entropy_losses))\n",
    "cross_entropy = get_mean_cross_entropy(df_fake, gru_model)\n",
    "\n",
    "assert np.isclose(CROSS_ENTROPY_MEAN, cross_entropy[\"mean\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_MEDIAN, cross_entropy[\"median\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_STD, cross_entropy[\"std\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_MAD, cross_entropy[\"mad\"], atol=1.0e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_losses = []\n",
    "for mthd in df_fake.code.values:\n",
    "    inputs = trnsfr_model.tokenize(mthd)\n",
    "    probs = trnsfr_model.get_probs(inputs)[0].numpy()\n",
    "\n",
    "    losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        inputs[\"input_ids\"], probs\n",
    "    ).numpy()\n",
    "    cross_entropy_losses.append(losses)\n",
    "\n",
    "CROSS_ENTROPY_MEAN = np.mean(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_MEDIAN = np.median(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_STD = np.std(np.concatenate(cross_entropy_losses))\n",
    "CROSS_ENTROPY_MAD = stats.median_abs_deviation(np.concatenate(cross_entropy_losses))\n",
    "cross_entropy = get_mean_cross_entropy(df_fake, trnsfr_model)\n",
    "\n",
    "assert np.isclose(CROSS_ENTROPY_MEAN, cross_entropy[\"mean\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_MEDIAN, cross_entropy[\"median\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_STD, cross_entropy[\"std\"], atol=1.0e-6)\n",
    "assert np.isclose(CROSS_ENTROPY_MAD, cross_entropy[\"mad\"], atol=1.0e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "_TRANSFORMs = {\n",
    "#     \"randomized_tokens\": code_token_randomizer,\n",
    "#     \"randomized_lines\": line_randomizer,\n",
    "    \"comments_removed\": java_comment_remover,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/dvc-icodegen/models/gru_layers1_vocab10000_embed256_units512\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "No matching opening parens at: 17",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-b9862402900b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"dvc-icodegen/datasets\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"dvc-icodegen/models\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;31m# Long-Range Interactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m#         results[m_path.name][\"long_range\"] = _long_range(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-b9862402900b>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(data_path, model_path)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# Long-Range Interactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         results[m_path.name][\"long_range\"] = _long_range(\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mbigclone_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbugfix_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodesearchnet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         )\n",
      "\u001b[0;32m<ipython-input-26-b9862402900b>\u001b[0m in \u001b[0;36m_long_range\u001b[0;34m(bigclone_path, bugfix_path, codesearchnet_path, model, n)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     ]\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mlong_range_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"buggy\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_buggy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     df_fixed = pd.read_json(bugfix_path / \"fixed.jsonl\", orient=\"records\", lines=True)[\n",
      "\u001b[0;32m<ipython-input-26-b9862402900b>\u001b[0m in \u001b[0;36m_get_metrics\u001b[0;34m(df, model)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmean_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mean_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_dist_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmean_cross_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mean_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-94c5f7e6a4eb>\u001b[0m in \u001b[0;36mmean_dist_probs\u001b[0;34m(df, model, opening, closing, n)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;31m# get the probabilities for the different distances for an entire dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     dist_probs = df.code.apply(\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mlambda\u001b[0m \u001b[0mmthd\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_get_dist_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmthd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopening\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     ).values\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-94c5f7e6a4eb>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(mthd)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     dist_probs = df.code.apply(\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mlambda\u001b[0m \u001b[0mmthd\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_get_dist_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmthd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopening\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     ).values\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-94c5f7e6a4eb>\u001b[0m in \u001b[0;36m_get_dist_probs\u001b[0;34m(mthd, model, opening, closing)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# get the distances for the opening and closing tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmthd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_parens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopening\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# get the model probabilities for the given method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-94c5f7e6a4eb>\u001b[0m in \u001b[0;36mfind_parens\u001b[0;34m(toks, opening, closing)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpstack\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No matching opening parens at: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtoret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: No matching opening parens at: 17"
     ]
    }
   ],
   "source": [
    "# export\n",
    "def _get_metrics(df, model):\n",
    "    mean_probs = get_mean_probs(df, model)\n",
    "    df_dist = mean_dist_probs(df, model)\n",
    "    mean_cross_entropy = get_mean_cross_entropy(df, model)\n",
    "\n",
    "    return {\n",
    "        \"mean_probs\": mean_probs,\n",
    "        \"dist_mean\": df_dist,\n",
    "        \"mean_cross_entropy\": mean_cross_entropy,\n",
    "    }\n",
    "\n",
    "\n",
    "# def _long_range(data_dir, model, n=None):\n",
    "#     long_range_results = {}\n",
    "\n",
    "#     df_buggy = pd.read_json(data_dir / \"buggy.jsonl\", orient=\"records\", lines=True)[:n]\n",
    "#     long_range_results[\"buggy\"] = _get_metrics(df_buggy, model)\n",
    "#     del df_buggy\n",
    "\n",
    "#     df_fixed = pd.read_json(data_dir / \"fixed.jsonl\", orient=\"records\", lines=True)[:n]\n",
    "#     long_range_results[\"fixed\"] = _get_metrics(df_fixed, model)\n",
    "#     del df_fixed\n",
    "\n",
    "#     df_codesearchnet = pd.read_json(\n",
    "#         data_dir / \"codesearchnet_java\" / \"test.jsonl\", orient=\"records\", lines=True\n",
    "#     )[:n]\n",
    "#     long_range_results[\"codesearchnet_original\"] = _get_metrics(df_codesearchnet, model)\n",
    "\n",
    "#     for transform in _TRANSFORMs:\n",
    "#         df_transformed = transform_df(df_codesearchnet, _TRANSFORMs[transform])\n",
    "#         long_range_results[\"codesearchnet_\" + transform] = _get_metrics(\n",
    "#             df_transformed, model\n",
    "#         )\n",
    "#         del df_transformed\n",
    "\n",
    "#     return long_range_results\n",
    "\n",
    "\n",
    "def _long_range(bigclone_path, bugfix_path, codesearchnet_path, model, n=None):\n",
    "    long_range_results = {}\n",
    "\n",
    "    # TODO add bigclone data\n",
    "\n",
    "    df_buggy = pd.read_json(bugfix_path / \"buggy.jsonl\", orient=\"records\", lines=True)[\n",
    "        :n\n",
    "    ]\n",
    "    long_range_results[\"buggy\"] = _get_metrics(df_buggy, model)\n",
    "\n",
    "    df_fixed = pd.read_json(bugfix_path / \"fixed.jsonl\", orient=\"records\", lines=True)[\n",
    "        :n\n",
    "    ]\n",
    "    long_range_results[\"fixed\"] = _get_metrics(df_fixed, model)\n",
    "\n",
    "#     df_codesearchnet = pd.read_json(\n",
    "#         codesearchnet_path / \"codesearchnet_java\" / \"test.jsonl\",\n",
    "#         orient=\"records\",\n",
    "#         lines=True,\n",
    "#     )[:n]\n",
    "#     long_range_results[\"codesearchnet_original\"] = _get_metrics(df_codesearchnet, model)\n",
    "\n",
    "#     for transform in _TRANSFORMs:\n",
    "#         df_transformed = transform_df(df_codesearchnet, _TRANSFORMs[transform])\n",
    "#         long_range_results[\"codesearchnet_\" + transform] = _get_metrics(\n",
    "#             df_transformed, model\n",
    "#         )\n",
    "\n",
    "    return long_range_results\n",
    "\n",
    "\n",
    "def _counterfactual(control_results, treatment_results):\n",
    "    pass\n",
    "\n",
    "\n",
    "def evaluate(data_path, model_path):\n",
    "    \"\"\"Function for evaluating models related to the library.\"\"\"\n",
    "    results = defaultdict(dict)\n",
    "    testbed_path = data_path / \"controlled/testbeds\"\n",
    "    #     models = []\n",
    "    # These model folders will need to contain the config of the model as well\n",
    "    # to differentiate them\n",
    "    for m_path in model_path.glob(\"*/\"):\n",
    "        model = None\n",
    "        print(m_path)\n",
    "        if m_path.name == \"Transformer\":\n",
    "            model = TransformerModel.from_path(m_path)\n",
    "        elif \"gru\" in m_path.name:\n",
    "            model = RNNModel.from_path(m_path)\n",
    "        elif m_path.name == \"RNN\":\n",
    "            pass\n",
    "#         return model\n",
    "    \n",
    "        bigclone_path = testbed_path / \"_ts_bigclone_types\"\n",
    "        bugfix_path = testbed_path / \"_ts_bug_fix\"\n",
    "        codesearchnet_path = testbed_path / \"codesearchnet\"\n",
    "\n",
    "        # Long-Range Interactions\n",
    "        results[m_path.name][\"long_range\"] = _long_range(\n",
    "            bigclone_path, bugfix_path, codesearchnet_path, model\n",
    "        )\n",
    "    return results\n",
    "\n",
    "\n",
    "path = Path(\"/home/jovyan/work\")\n",
    "data_path = path / \"dvc-icodegen/datasets\"\n",
    "model_path = path / \"dvc-icodegen/models\"\n",
    "results = evaluate(data_path, model_path)\n",
    "        # Long-Range Interactions\n",
    "#         results[m_path.name][\"long_range\"] = _long_range(\n",
    "#             bigclone_path, bugfix_path, codesearchnet_path, model\n",
    "#         )\n",
    "\n",
    "#     return results\n",
    "    # Counterfactuals\n",
    "\n",
    "\n",
    "#         results[m_path][\"counterfactual\"] = _counterfactual(data_dir, model)\n",
    "# _counterfactual(control_results, treatment_results)\n",
    "\n",
    "# Save results in json format\n",
    "# Long-Range Interactions\n",
    "#     long_range_results = _long_range(data_dir, models)\n",
    "#     long_range_results\n",
    "\n",
    "#     # Counterfactuals\n",
    "#     counterfactual_results = []\n",
    "#     counterfactual_results\n",
    "#     for transform in _TRANSFORMs:\n",
    "#         pass\n",
    "# _counterfactual(control_results, treatment_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_range_results = _long_range(Path(\"/tmp\"), model, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_data.core.ipynb.\n",
      "Converted 01_data.transforms.ipynb.\n",
      "Converted 02_model.core.ipynb.\n",
      "Converted 04_evaluation.core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
