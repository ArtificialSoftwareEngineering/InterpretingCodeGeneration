{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch NB for prototyping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting to extract probabilities from tf huggingface model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6, 50257), dtype=float32, numpy=\n",
       "array([[[ -35.17591 ,  -35.26997 ,  -38.91764 , ...,  -44.395615,\n",
       "          -43.92903 ,  -36.39843 ],\n",
       "        [-112.56821 , -114.53677 , -116.5203  , ..., -118.96662 ,\n",
       "         -118.75463 , -111.64338 ],\n",
       "        [ -88.70529 ,  -89.833115,  -93.1642  , ...,  -92.35576 ,\n",
       "          -96.1465  ,  -92.0973  ],\n",
       "        [ -85.133896,  -88.31175 ,  -92.842514, ...,  -99.773056,\n",
       "          -94.740005,  -90.902916],\n",
       "        [-116.72396 , -119.39425 , -121.721405, ..., -129.09853 ,\n",
       "         -124.60782 , -121.60594 ],\n",
       "        [ -77.45214 ,  -80.45671 ,  -88.05355 , ...,  -96.26563 ,\n",
       "          -93.64352 ,  -84.07373 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = TFGPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n",
    "outputs = model(inputs)\n",
    "logits = outputs[0]\n",
    "probs = tf.nn.softmax(logits); probs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icodegen",
   "language": "python",
   "name": "icodegen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
