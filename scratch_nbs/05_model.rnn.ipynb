{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model.rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n",
    "\n",
    "> API details. @nathan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from icodegen.data.core import convert_df_to_tfds\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# Setup\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"sshleifer/tiny-gpt2\")\n",
    "tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "\n",
    "df_fake = pd.DataFrame(\n",
    "    [\"aaaa(bb(aaaa(bb()()ccc)dd)()ccc)dd\", \"aaaa(bb()ccccc)dd\"], columns=[\"code\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        labels, logits, from_logits=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class RNNModel:\n",
    "    _RNN_TYPE = {\n",
    "        \"rnn\": tf.keras.layers.SimpleRNN,\n",
    "        \"gru\": tf.keras.layers.GRU,\n",
    "        \"lstm\": tf.keras.layers.LSTM,\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        rnn_type,\n",
    "        n_layers,\n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        rnn_units,\n",
    "        batch_size,\n",
    "        out_path,\n",
    "        tokenizer,\n",
    "    ):\n",
    "        layer = RNNModel._RNN_TYPE[rnn_type]\n",
    "        rnn_layers = [\n",
    "            layer(\n",
    "                rnn_units,\n",
    "                return_sequences=True,\n",
    "                # I think we need to have this not be stateful since we don't\n",
    "                # chop up examples\n",
    "                # stateful=True,\n",
    "                recurrent_initializer=\"glorot_uniform\",\n",
    "                # following BigCode != Big Vocab Paper\n",
    "                dropout=0.1,\n",
    "            )\n",
    "            for _ in range(n_layers)\n",
    "        ]\n",
    "        self.model = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=vocab_size,\n",
    "                    output_dim=embedding_dim,\n",
    "                    mask_zero=True,  # Zero cannot be used in the vocabulary\n",
    "                    batch_input_shape=[batch_size, None],\n",
    "                ),\n",
    "            ]\n",
    "            + rnn_layers\n",
    "            + [\n",
    "                tf.keras.layers.Dense(vocab_size),\n",
    "            ]\n",
    "        )\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.config_name = (\n",
    "            f\"{rnn_type}_vocab{vocab_size}_embed{embedding_dim}_units{rnn_units}\"\n",
    "        )\n",
    "        self.out_path = Path(out_path) / self.config_name\n",
    "        self.callbacks = [\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=self.out_path / \"ckpt_{epoch}\", save_weights_only=True\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    # TODO add code to easily train model\n",
    "    def train(self, dataset, epochs):\n",
    "        self.model.compile(optimizer=\"adam\", loss=_loss)\n",
    "        _ = self.model.fit(dataset, epochs=epochs, callbacks=self.callbacks)\n",
    "\n",
    "    def generate(self, n, temperature=1.0):\n",
    "        # Evaluation step (generating text using the learned model)\n",
    "\n",
    "        # Converting our start string to numbers (vectorizing)\n",
    "        input_eval = [self.tokenizer.bos_token_id]\n",
    "        input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "        # Empty string to store our results\n",
    "        text_generated = []\n",
    "\n",
    "        # Low temperature results in more predictable text.\n",
    "        # Higher temperature results in more surprising text.\n",
    "        # Experiment to find the best setting.\n",
    "        #         temperature = 1.0\n",
    "\n",
    "        # Here batch size == 1\n",
    "        self.model.reset_states()\n",
    "        for i in range(n):\n",
    "            predictions = self.model(input_eval)\n",
    "            # remove the batch dimension\n",
    "            predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "            # using a categorical distribution to predict the character returned by the model\n",
    "            predictions = predictions / temperature\n",
    "            predicted_id = tf.random.categorical(predictions, num_samples=1)[\n",
    "                -1, 0\n",
    "            ].numpy()\n",
    "\n",
    "            # Pass the predicted character as the next input to the model\n",
    "            # along with the previous hidden state\n",
    "            input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "            text_generated.append(predicted_id)\n",
    "\n",
    "        return self.tokenizer.decode(text_generated), text_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "ds = convert_df_to_tfds(df_fake, tokenizer, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (1, None, 128)            6433024   \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (1, None, 128)            99072     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (1, None, 50258)          6483282   \n",
      "=================================================================\n",
      "Total params: 13,015,378\n",
      "Trainable params: 13,015,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gru = RNNModel(\"gru\", 1, len(tokenizer), 128, 128, 1, \"/tmp\", tokenizer)\n",
    "gru.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 2.8198\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 1s 256ms/step - loss: 2.5743\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 1s 255ms/step - loss: 2.3716\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 2.2085\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 1s 552ms/step - loss: 2.0894\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 1s 484ms/step - loss: 1.9924\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 1.9206\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 1s 498ms/step - loss: 1.8710\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 1s 546ms/step - loss: 1.8355\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 1s 541ms/step - loss: 1.8127\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 1s 593ms/step - loss: 1.7924\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 1s 554ms/step - loss: 1.7773\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 1s 594ms/step - loss: 1.7669\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 1s 574ms/step - loss: 1.7526\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 1s 596ms/step - loss: 1.7407\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 1s 598ms/step - loss: 1.7340\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 1s 519ms/step - loss: 1.7318\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 1s 565ms/step - loss: 1.7168\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 1s 552ms/step - loss: 1.7130\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 1s 561ms/step - loss: 1.7041\n"
     ]
    }
   ],
   "source": [
    "gru.train(ds, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[PAD] aaaacc incor Resolerance Damon Chloeablishment tours',\n",
       " [50257, 24794, 535, 5970, 1874, 37668, 33572, 29476, 25380, 21284])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru.generate(10, temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
