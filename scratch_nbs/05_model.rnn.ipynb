{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model.rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n",
    "\n",
    "> API details. @nathan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# Setup\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"sshleifer/tiny-gpt2\")\n",
    "tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "\n",
    "df_fake = pd.DataFrame(\n",
    "    [\"aaaa(bb(aaaa(bb()()ccc)dd)()ccc)dd\", \"aaaa(bb()ccccc)dd\"], columns=[\"code\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        labels, logits, from_logits=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class GRUModel(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self, n_layers, vocab_size, embedding_dim, rnn_units, batch_size, out_path\n",
    "    ):\n",
    "        super(GRUModel, self).__init__()\n",
    "        gru_layers = [\n",
    "            tf.keras.layers.GRU(\n",
    "                rnn_units,\n",
    "                return_sequences=True,\n",
    "                # I think we need to have this not be stateful since we don't\n",
    "                # chop up examples\n",
    "                # stateful=True,\n",
    "                recurrent_initializer=\"glorot_uniform\",\n",
    "                # following BigCode != Big Vocab Paper\n",
    "                dropout=0.1,\n",
    "            )\n",
    "            for _ in range(n_layers)\n",
    "        ]\n",
    "        self.model = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=vocab_size,\n",
    "                    output_dim=embedding_dim,\n",
    "                    mask_zero=True,  # Zero cannot be used in the vocabulary\n",
    "                    batch_input_shape=[batch_size, None],\n",
    "                ),\n",
    "            ]\n",
    "            + gru_layers\n",
    "            + [\n",
    "                tf.keras.layers.Dense(vocab_size),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.config_name = (\n",
    "            f\"gru_vocab{vocab_size}_embed{embedding_dim}_units{rnn_units}\"\n",
    "        )\n",
    "        self.out_path = Path(out_path) / self.config_name\n",
    "        checkpoint_prefix = self.out_path / self.config_name / \"ckpt_{epoch}\"\n",
    "        self.callbacks = [\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_prefix, save_weights_only=True\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    def call(self, batch):\n",
    "        return self.model(batch)\n",
    "\n",
    "    # TODO add code to easily train model\n",
    "    def train(self, dataset, epochs):\n",
    "        self.compile(optimizer=\"adam\", loss=_loss)\n",
    "        _ = self.model.fit(dataset, epochs=epochs, callbacks=self.callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "tokenized_mthds = [\n",
    "    tokenizer.encode(mthd, max_length=32, padding=\"max_length\")\n",
    "    for mthd in df_fake.code.values\n",
    "]\n",
    "ds = tf.data.Dataset.from_tensor_slices(tokenized_mthds).batch(2, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (1, None, 256)            12866048  \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, None, 50258)          51514450  \n",
      "=================================================================\n",
      "Total params: 68,318,802\n",
      "Trainable params: 68,318,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gru = GRUModel(1, len(tokenizer), 256, 1024, 1)\n",
    "gru.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in ds.take(1):\n",
    "    output = gru(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 32, 50258), dtype=float32, numpy=\n",
       "array([[[ 1.1789987e-03, -1.0764061e-03, -7.0536515e-04, ...,\n",
       "         -1.8938105e-03,  3.0941013e-04,  5.4561184e-04],\n",
       "        [ 6.6408433e-04, -3.6950165e-04,  2.1222243e-03, ...,\n",
       "         -1.6042381e-03,  6.4406340e-05, -3.4853775e-04],\n",
       "        [ 1.7635215e-03, -2.3366189e-04,  2.0413476e-03, ...,\n",
       "          1.0840559e-03, -8.7091571e-04,  2.6355719e-03],\n",
       "        ...,\n",
       "        [-2.8481015e-03,  1.8251555e-03,  1.5210311e-03, ...,\n",
       "          1.9312165e-03,  1.0953154e-03,  1.0994463e-03],\n",
       "        [-2.8373816e-03,  1.8310322e-03,  1.5131955e-03, ...,\n",
       "          1.9235963e-03,  1.1112771e-03,  1.1064576e-03],\n",
       "        [-2.8300122e-03,  1.8353187e-03,  1.5077242e-03, ...,\n",
       "          1.9177452e-03,  1.1218428e-03,  1.1099423e-03]],\n",
       "\n",
       "       [[ 1.1789987e-03, -1.0764061e-03, -7.0536515e-04, ...,\n",
       "         -1.8938105e-03,  3.0941013e-04,  5.4561184e-04],\n",
       "        [ 6.6408433e-04, -3.6950165e-04,  2.1222243e-03, ...,\n",
       "         -1.6042381e-03,  6.4406340e-05, -3.4853775e-04],\n",
       "        [ 1.7635215e-03, -2.3366189e-04,  2.0413476e-03, ...,\n",
       "          1.0840559e-03, -8.7091571e-04,  2.6355719e-03],\n",
       "        ...,\n",
       "        [-2.8163712e-03,  1.8434778e-03,  1.4978438e-03, ...,\n",
       "          1.9025782e-03,  1.1401066e-03,  1.1101761e-03],\n",
       "        [-2.8162291e-03,  1.8435416e-03,  1.4977863e-03, ...,\n",
       "          1.9022636e-03,  1.1402216e-03,  1.1100119e-03],\n",
       "        [-2.8161344e-03,  1.8435771e-03,  1.4977602e-03, ...,\n",
       "          1.9020434e-03,  1.1402845e-03,  1.1098958e-03]]], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
